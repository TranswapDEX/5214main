{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used code from this tutorial:\n",
    "# https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Collaborative%20Filtering%20Model%20with%20TensorFlow.ipynb\n",
    "# And we also used code from this tutorial:\n",
    "# https://medium.com/@connectwithghosh/recommender-system-on-the-movielens-using-an-autoencoder-using-tensorflow-in-python-f13d3e8d600d\n",
    "# Then, we integrated these two tutorials and edited the code from each of them in order to create a recommender that allows us to recommend a top 10 list of movies without needing to retrain for each new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.read_csv('/Users/blakemyers/Desktop/Jupyter/ml-1m/ratings.csv', sep = \"::\", error_bad_lines=False, encoding='latin-1', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating.rename({\"1\": \"userId\", \"1193\": \"movieId\", \"5\": \"rating\", \"978300760\": \"timestamp\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv(\"/Users/blakemyers/Desktop/Jupyter/ml-1m/movies.csv\", sep = \"::\", error_bad_lines=False, encoding='latin-1', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.rename({\"1\": \"movieId\", \"Toy Story (1995)\": \"title\", \"Animation|Children's|Comedy\": \"genre\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating = pd.merge(rating, movie, on = 'movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie = movie_rating.groupby(\"title\")[\"rating\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie.rename({\"rating\": \"ratecount_movie\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie = numrate_movie.query(\"ratecount_movie >= 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings20plus = pd.merge(numrate_movie, movie_rating, on = 'title', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user = ratings20plus.groupby(\"userId\")[\"rating\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user.rename({\"rating\": \"ratecount_user\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user = numrate_user.query(\"ratecount_user >= 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus = pd.merge(ratings20plus, numrate_user, on = \"userId\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float) #set rating values as float\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "#place the rating values on a scale from -1 to 1\n",
    "ur20plus['rating'] = rating_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title']) #drop duplicates\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "#create matrix (see below)\n",
    "user_movie_matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(user_movie_matrix, train_size=0.8)\n",
    "#split the training data (80%) from the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/blakemyers/opt/anaconda3/envs/tf_environment/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = ur20plus['title'].nunique()\n",
    "# Deciding how many nodes each layer should have\n",
    "n_nodes_inpl = num_input\n",
    "n_nodes_hl1  = 256\n",
    "n_nodes_outl = num_input  \n",
    "# first hidden layer has num_input*32 weights and 32 biases\n",
    "hidden_1_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_inpl+1,n_nodes_hl1]))}\n",
    "# first hidden layer has 784*32 weights and 32 biases\n",
    "output_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1+1,n_nodes_outl]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/blakemyers/opt/anaconda3/envs/tf_environment/lib/python3.7/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.placeholder('float', [None, num_input])\n",
    "# add a constant node to the first layer\n",
    "# it needs to have the same shape as the input layer to be able to concatinate it later\n",
    "input_layer_const = tf.fill( [tf.shape(input_layer)[0], 1] ,1.0  )\n",
    "input_layer_concat =  tf.concat([input_layer, input_layer_const], 1)\n",
    "# multiply output of input_layer wth a weight matrix \n",
    "layer_1 = tf.nn.sigmoid(tf.matmul(input_layer_concat,\\\n",
    "hidden_1_layer_vals['weights']))\n",
    "# adding one bias node to the hidden layer\n",
    "layer1_const = tf.fill( [tf.shape(layer_1)[0], 1] ,1.0  )\n",
    "layer_concat =  tf.concat([layer_1, layer1_const], 1)\n",
    "# multiply output of hidden with a weight matrix to get final output\n",
    "output_layer = tf.matmul( layer_concat,output_layer_vals['weights'])\n",
    "# output_true shall have the original shape for error calculations\n",
    "output_true = tf.placeholder('float', [None, num_input])\n",
    "# define cost function\n",
    "meansq =    tf.reduce_mean(tf.square(output_layer - output_true))\n",
    "# define optimizer\n",
    "learn_rate = 0.1   # how fast the model should learn\n",
    "optimizer = tf.train.AdagradOptimizer(learn_rate).minimize(meansq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising variables and starting the session\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "# defining batch size, number of epochs and learning rate\n",
    "batch_size = 100  # how many images to use together for training\n",
    "hm_epochs =200    # how many times to go through the entire dataset\n",
    "tot_images = X_train.shape[0] # total number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 47.33322552707516 MSE test 47.66235407544632\n",
      "Epoch 0 / 200 loss: 3369.5045585632324\n",
      "MSE train 31.82029214577246 MSE test 32.12288942770701\n",
      "Epoch 1 / 200 loss: 1864.8186874389648\n",
      "MSE train 23.002835928291617 MSE test 23.313781267497642\n",
      "Epoch 2 / 200 loss: 1308.6255264282227\n",
      "MSE train 17.31630950714615 MSE test 17.640273979014836\n",
      "Epoch 3 / 200 loss: 962.9341869354248\n",
      "MSE train 13.651031132623123 MSE test 13.978598063326821\n",
      "Epoch 4 / 200 loss: 741.0655899047852\n",
      "MSE train 11.203037601157735 MSE test 11.54220825776259\n",
      "Epoch 5 / 200 loss: 595.8883638381958\n",
      "MSE train 9.489249806754174 MSE test 9.819184408093907\n",
      "Epoch 6 / 200 loss: 496.85125637054443\n",
      "MSE train 8.232115272382378 MSE test 8.552192322270109\n",
      "Epoch 7 / 200 loss: 425.91702032089233\n",
      "MSE train 7.2709559488057405 MSE test 7.581273095620975\n",
      "Epoch 8 / 200 loss: 372.77850675582886\n",
      "MSE train 6.515658207176975 MSE test 6.816627401154747\n",
      "Epoch 9 / 200 loss: 331.63193130493164\n",
      "MSE train 5.908172122480018 MSE test 6.195790088397789\n",
      "Epoch 10 / 200 loss: 298.9260730743408\n",
      ".......................\n",
      "MSE train 0.18653155854591952 MSE test 0.35120803184432375\n",
      "Epoch 190 / 200 loss: 8.991316445171833\n",
      "MSE train 0.18494444919372566 MSE test 0.3495088972983642\n",
      "Epoch 191 / 200 loss: 8.914478532969952\n",
      "MSE train 0.18337864140829677 MSE test 0.3478321514446097\n",
      "Epoch 192 / 200 loss: 8.838684424757957\n",
      "MSE train 0.18183350519064334 MSE test 0.3461773769585869\n",
      "Epoch 193 / 200 loss: 8.763904303312302\n",
      "MSE train 0.1803084088499581 MSE test 0.3445441793407014\n",
      "Epoch 194 / 200 loss: 8.69010765105486\n",
      "MSE train 0.1788027328462541 MSE test 0.3429321673221303\n",
      "Epoch 195 / 200 loss: 8.617265172302723\n",
      "MSE train 0.17731589236016868 MSE test 0.34134097327678337\n",
      "Epoch 196 / 200 loss: 8.545346558094025\n",
      "MSE train 0.17584735437312768 MSE test 0.3397702384441526\n",
      "Epoch 197 / 200 loss: 8.474324099719524\n",
      "MSE train 0.1743967023422907 MSE test 0.3382196694615361\n",
      "Epoch 198 / 200 loss: 8.404173262417316\n",
      "MSE train 0.17296367585962166 MSE test 0.3366890068557748\n",
      "Epoch 199 / 200 loss: 8.334874622523785\n"
     ]
    }
   ],
   "source": [
    "# running the model for a 200 epochs taking 100 users in batches\n",
    "# total improvement is printed out after each epoch\n",
    "for epoch in range(hm_epochs):\n",
    "    epoch_loss = 0    # initializing loss (error) as 0\n",
    "    \n",
    "    for i in range(int(tot_images/batch_size)):\n",
    "        epoch_x = X_train[ i*batch_size : (i+1)*batch_size ]\n",
    "        _, c = sess.run([optimizer, meansq],\\\n",
    "               feed_dict={input_layer: epoch_x, \\\n",
    "               output_true: epoch_x})\n",
    "        epoch_loss += c\n",
    "        \n",
    "    output_train = sess.run(output_layer,\\\n",
    "               feed_dict={input_layer:X_train})\n",
    "    output_test = sess.run(output_layer,\\\n",
    "                   feed_dict={input_layer:X_test})\n",
    "        \n",
    "    if epoch <= 10 or epoch >= 190:\n",
    "        print('MSE train', MSE(output_train, X_train),'MSE test', MSE(output_test, X_test))\n",
    "        print('Epoch', epoch, '/', hm_epochs, 'loss:',epoch_loss)\n",
    "    elif epoch == 11:\n",
    "        print('.......................')\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18298879</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Hear My Song (1991)</td>\n",
       "      <td>3.023763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18300570</th>\n",
       "      <td>9999991</td>\n",
       "      <td>West Side Story (1961)</td>\n",
       "      <td>2.915480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18298423</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Doom Generation, The (1995)</td>\n",
       "      <td>2.708492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18300253</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Stonewall (1995)</td>\n",
       "      <td>2.351707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18299441</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Modern Times (1936)</td>\n",
       "      <td>2.343343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18298516</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Everything You Always Wanted to Know About Sex...</td>\n",
       "      <td>2.338465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18299362</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Matilda (1996)</td>\n",
       "      <td>2.268787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18298665</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Freeway (1996)</td>\n",
       "      <td>2.265756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18299125</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Karate Kid, The (1984)</td>\n",
       "      <td>2.200862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18299862</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Puppet Master III: Toulon's Revenge (1991)</td>\n",
       "      <td>2.199547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userId                                              title    rating\n",
       "18298879  9999991                                Hear My Song (1991)  3.023763\n",
       "18300570  9999991                             West Side Story (1961)  2.915480\n",
       "18298423  9999991                        Doom Generation, The (1995)  2.708492\n",
       "18300253  9999991                                   Stonewall (1995)  2.351707\n",
       "18299441  9999991                                Modern Times (1936)  2.343343\n",
       "18298516  9999991  Everything You Always Wanted to Know About Sex...  2.338465\n",
       "18299362  9999991                                     Matilda (1996)  2.268787\n",
       "18298665  9999991                                     Freeway (1996)  2.265756\n",
       "18299125  9999991                             Karate Kid, The (1984)  2.200862\n",
       "18299862  9999991         Puppet Master III: Toulon's Revenge (1991)  2.199547"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a top 10 ranking for a new user (9999991) who rates \"Chariots of Fire (1981)\" with a 5\n",
    "ur20plus = ur20plus.append(pd.DataFrame([[\"Chariots of Fire (1981)\",1,9999991,1,5,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)\n",
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float)\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "ur20plus['rating'] = rating_scaled\n",
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title'])\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "user_movie_matrix.fillna(0, inplace=True)\n",
    "pred_data = pd.DataFrame()\n",
    "preds = sess.run(output_layer, feed_dict={input_layer: user_movie_matrix})\n",
    "pred_data = pred_data.append(pd.DataFrame(preds))\n",
    "pred_data = pred_data.stack().reset_index(name='rating')\n",
    "pred_data.columns = ['userId', 'title', 'rating']\n",
    "users = user_movie_matrix.index.tolist()\n",
    "movies = user_movie_matrix.columns.tolist()\n",
    "pred_data['userId'] = pred_data['userId'].map(lambda value: users[value])\n",
    "pred_data['title'] = pred_data['title'].map(lambda value: movies[value])\n",
    "keys = ['userId', 'title']\n",
    "index_1 = pred_data.set_index(keys).index\n",
    "index_2 = ur20plus.set_index(keys).index\n",
    "top_ten_ranked = pred_data[~index_1.isin(index_2)]\n",
    "top_ten_ranked = top_ten_ranked.sort_values(['userId', 'rating'], ascending=[True, False])\n",
    "top_ten_ranked = top_ten_ranked.groupby('userId').head(10)\n",
    "top_ten_ranked.loc[top_ten_ranked['userId'] == 9999991]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18301102</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Breakfast of Champions (1999)</td>\n",
       "      <td>2.948779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18302323</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Love Letter, The (1999)</td>\n",
       "      <td>2.667478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18300795</th>\n",
       "      <td>9999992</td>\n",
       "      <td>American Werewolf in Paris, An (1997)</td>\n",
       "      <td>2.570849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18303691</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Wrongfully Accused (1998)</td>\n",
       "      <td>2.473479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18302629</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Night to Remember, A (1958)</td>\n",
       "      <td>2.405450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18303072</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Saving Private Ryan (1998)</td>\n",
       "      <td>2.399654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18300697</th>\n",
       "      <td>9999992</td>\n",
       "      <td>8 1/2 (1963)</td>\n",
       "      <td>2.369504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18302054</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Immortal Beloved (1994)</td>\n",
       "      <td>2.326427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18302409</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Maximum Overdrive (1986)</td>\n",
       "      <td>2.313506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18300865</th>\n",
       "      <td>9999992</td>\n",
       "      <td>At First Sight (1999)</td>\n",
       "      <td>2.271835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userId                                  title    rating\n",
       "18301102  9999992          Breakfast of Champions (1999)  2.948779\n",
       "18302323  9999992                Love Letter, The (1999)  2.667478\n",
       "18300795  9999992  American Werewolf in Paris, An (1997)  2.570849\n",
       "18303691  9999992              Wrongfully Accused (1998)  2.473479\n",
       "18302629  9999992            Night to Remember, A (1958)  2.405450\n",
       "18303072  9999992             Saving Private Ryan (1998)  2.399654\n",
       "18300697  9999992                           8 1/2 (1963)  2.369504\n",
       "18302054  9999992                Immortal Beloved (1994)  2.326427\n",
       "18302409  9999992               Maximum Overdrive (1986)  2.313506\n",
       "18300865  9999992                  At First Sight (1999)  2.271835"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a top 10 ranking for a new user (9999992) who rates \"Hurricane, The (1999)\" with a 3\n",
    "ur20plus = ur20plus.append(pd.DataFrame([[\"Hurricane, The (1999)\",1,9999992,1,3,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)\n",
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float)\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "ur20plus['rating'] = rating_scaled\n",
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title'])\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "user_movie_matrix.fillna(0, inplace=True)\n",
    "pred_data = pd.DataFrame()\n",
    "preds = sess.run(output_layer, feed_dict={input_layer: user_movie_matrix})\n",
    "pred_data = pred_data.append(pd.DataFrame(preds))\n",
    "pred_data = pred_data.stack().reset_index(name='rating')\n",
    "pred_data.columns = ['userId', 'title', 'rating']\n",
    "users = user_movie_matrix.index.tolist()\n",
    "movies = user_movie_matrix.columns.tolist()\n",
    "pred_data['userId'] = pred_data['userId'].map(lambda value: users[value])\n",
    "pred_data['title'] = pred_data['title'].map(lambda value: movies[value])\n",
    "keys = ['userId', 'title']\n",
    "index_1 = pred_data.set_index(keys).index\n",
    "index_2 = ur20plus.set_index(keys).index\n",
    "top_ten_ranked = pred_data[~index_1.isin(index_2)]\n",
    "top_ten_ranked = top_ten_ranked.sort_values(['userId', 'rating'], ascending=[True, False])\n",
    "top_ten_ranked = top_ten_ranked.groupby('userId').head(10)\n",
    "top_ten_ranked.loc[top_ten_ranked['userId'] == 9999992]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
