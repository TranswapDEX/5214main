{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used this tutorial:\n",
    "# https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Collaborative%20Filtering%20Model%20with%20TensorFlow.ipynb\n",
    "# And we also used code from this tutorial:\n",
    "# https://medium.com/@connectwithghosh/recommender-system-on-the-movielens-using-an-autoencoder-using-tensorflow-in-python-f13d3e8d600d\n",
    "# Then, we integrated these two tutorials and edited the code from each of them in order to create\n",
    "# a recommender that allows us to recommend a top 10 list of movies\n",
    "# without needing to retrain for each new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.read_csv('/Users/blakemyers/Desktop/data/ratings.csv', error_bad_lines=False, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv(\"/Users/blakemyers/Desktop/data/movies.csv\", error_bad_lines=False, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating = pd.merge(rating, movie, on = 'movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie = movie_rating.groupby(\"title\")[\"rating\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie.rename({\"rating\": \"ratecount_movie\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie = numrate_movie.query(\"ratecount_movie >= 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings20plus = pd.merge(numrate_movie, movie_rating, on = 'title', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user = ratings20plus.groupby(\"userId\")[\"rating\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user.rename({\"rating\": \"ratecount_user\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user = numrate_user.query(\"ratecount_user >= 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus = pd.merge(ratings20plus, numrate_user, on = \"userId\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus = ur20plus.append(pd.DataFrame([[\"A.I. Artificial Intelligence (2001)\",1,9999999,4370,5,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float)\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "ur20plus['rating'] = rating_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title'])\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "user_movie_matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>(500) Days of Summer (2009)</th>\n",
       "      <th>10 Things I Hate About You (1999)</th>\n",
       "      <th>101 Dalmatians (1996)</th>\n",
       "      <th>101 Dalmatians (One Hundred and One Dalmatians) (1961)</th>\n",
       "      <th>12 Angry Men (1957)</th>\n",
       "      <th>13 Going on 30 (2004)</th>\n",
       "      <th>13th Warrior, The (1999)</th>\n",
       "      <th>1408 (2007)</th>\n",
       "      <th>2001: A Space Odyssey (1968)</th>\n",
       "      <th>2012 (2009)</th>\n",
       "      <th>...</th>\n",
       "      <th>Young Frankenstein (1974)</th>\n",
       "      <th>Young Guns (1988)</th>\n",
       "      <th>Zack and Miri Make a Porno (2008)</th>\n",
       "      <th>Zodiac (2007)</th>\n",
       "      <th>Zombieland (2009)</th>\n",
       "      <th>Zoolander (2001)</th>\n",
       "      <th>Zootopia (2016)</th>\n",
       "      <th>eXistenZ (1999)</th>\n",
       "      <th>xXx (2002)</th>\n",
       "      <th>Â¡Three Amigos! (1986)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "title   (500) Days of Summer (2009)  10 Things I Hate About You (1999)  \\\n",
       "userId                                                                   \n",
       "1                               0.0                                0.0   \n",
       "2                               0.0                                0.0   \n",
       "3                               0.0                                0.0   \n",
       "4                               0.0                                0.0   \n",
       "5                               0.0                                0.0   \n",
       "\n",
       "title   101 Dalmatians (1996)  \\\n",
       "userId                          \n",
       "1                         0.0   \n",
       "2                         0.0   \n",
       "3                         0.0   \n",
       "4                         0.0   \n",
       "5                         0.0   \n",
       "\n",
       "title   101 Dalmatians (One Hundred and One Dalmatians) (1961)  \\\n",
       "userId                                                           \n",
       "1                                                     0.0        \n",
       "2                                                     0.0        \n",
       "3                                                     0.0        \n",
       "4                                                     0.0        \n",
       "5                                                     0.0        \n",
       "\n",
       "title   12 Angry Men (1957)  13 Going on 30 (2004)  13th Warrior, The (1999)  \\\n",
       "userId                                                                         \n",
       "1                       0.0                    0.0                  0.777778   \n",
       "2                       0.0                    0.0                  0.000000   \n",
       "3                       0.0                    0.0                  0.000000   \n",
       "4                       1.0                    0.0                  0.000000   \n",
       "5                       0.0                    0.0                  0.000000   \n",
       "\n",
       "title   1408 (2007)  2001: A Space Odyssey (1968)  2012 (2009)  ...  \\\n",
       "userId                                                          ...   \n",
       "1               0.0                           0.0          0.0  ...   \n",
       "2               0.0                           0.0          0.0  ...   \n",
       "3               0.0                           0.0          0.0  ...   \n",
       "4               0.0                           0.0          0.0  ...   \n",
       "5               0.0                           0.0          0.0  ...   \n",
       "\n",
       "title   Young Frankenstein (1974)  Young Guns (1988)  \\\n",
       "userId                                                 \n",
       "1                             1.0                0.0   \n",
       "2                             0.0                0.0   \n",
       "3                             0.0                0.0   \n",
       "4                             0.0                0.0   \n",
       "5                             0.0                0.0   \n",
       "\n",
       "title   Zack and Miri Make a Porno (2008)  Zodiac (2007)  Zombieland (2009)  \\\n",
       "userId                                                                        \n",
       "1                                     0.0            0.0           0.000000   \n",
       "2                                     0.0            0.0           0.555556   \n",
       "3                                     0.0            0.0           0.000000   \n",
       "4                                     0.0            0.0           0.000000   \n",
       "5                                     0.0            0.0           0.000000   \n",
       "\n",
       "title   Zoolander (2001)  Zootopia (2016)  eXistenZ (1999)  xXx (2002)  \\\n",
       "userId                                                                   \n",
       "1                    0.0              0.0              0.0         0.0   \n",
       "2                    0.0              0.0              0.0         0.0   \n",
       "3                    0.0              0.0              0.0         0.0   \n",
       "4                    0.0              0.0              0.0         0.0   \n",
       "5                    0.0              0.0              0.0         0.0   \n",
       "\n",
       "title   Â¡Three Amigos! (1986)  \n",
       "userId                          \n",
       "1                     0.777778  \n",
       "2                     0.000000  \n",
       "3                     0.000000  \n",
       "4                     0.000000  \n",
       "5                     0.000000  \n",
       "\n",
       "[5 rows x 1297 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_movie_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(user_movie_matrix, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/blakemyers/opt/anaconda3/envs/tf_environment/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = ur20plus['title'].nunique()\n",
    "n_nodes_inpl = num_input  \n",
    "n_nodes_hl1  = 256  \n",
    "n_nodes_outl = num_input  \n",
    "hidden_1_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_inpl+1,n_nodes_hl1]))}\n",
    "output_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1+1,n_nodes_outl]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/blakemyers/opt/anaconda3/envs/tf_environment/lib/python3.7/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.placeholder('float', [None, num_input])\n",
    "input_layer_const = tf.fill( [tf.shape(input_layer)[0], 1] ,1.0  )\n",
    "input_layer_concat =  tf.concat([input_layer, input_layer_const], 1)\n",
    "layer_1 = tf.nn.sigmoid(tf.matmul(input_layer_concat,hidden_1_layer_vals['weights']))\n",
    "layer1_const = tf.fill( [tf.shape(layer_1)[0], 1] ,1.0  )\n",
    "layer_concat =  tf.concat([layer_1, layer1_const], 1)\n",
    "output_layer = tf.matmul( layer_concat,output_layer_vals['weights'])\n",
    "output_true = tf.placeholder('float', [None, num_input])\n",
    "meansq =    tf.reduce_mean(tf.square(output_layer - output_true))\n",
    "learn_rate = 0.1\n",
    "optimizer = tf.train.AdagradOptimizer(learn_rate).minimize(meansq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "batch_size = 100\n",
    "hm_epochs =200\n",
    "tot_images = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 91.82437661412699 MSE test 92.10847704744378\n",
      "Epoch 0 / 200 loss: 427.97928619384766\n",
      "MSE train 76.20612836340655 MSE test 76.80663097421993\n",
      "Epoch 1 / 200 loss: 341.9962387084961\n",
      "MSE train 65.95440004303283 MSE test 66.72087202261335\n",
      "Epoch 2 / 200 loss: 288.3486785888672\n",
      "MSE train 58.7957680528673 MSE test 59.65506569845345\n",
      "Epoch 3 / 200 loss: 252.37351989746094\n",
      "MSE train 53.55177847259794 MSE test 54.47840036702652\n",
      "Epoch 4 / 200 loss: 226.79779052734375\n",
      "MSE train 49.5754278476019 MSE test 50.55931642177745\n",
      "Epoch 5 / 200 loss: 207.84182357788086\n",
      "MSE train 46.470221322685575 MSE test 47.50893099301113\n",
      "Epoch 6 / 200 loss: 193.3106689453125\n",
      "MSE train 43.99391545289107 MSE test 45.08504024363708\n",
      "Epoch 7 / 200 loss: 181.86090850830078\n",
      "MSE train 41.979998188160735 MSE test 43.125833081700016\n",
      "Epoch 8 / 200 loss: 172.66121292114258\n",
      "MSE train 40.3065883587741 MSE test 41.51318499842421\n",
      "Epoch 9 / 200 loss: 165.11857986450195\n",
      "MSE train 38.88831852444306 MSE test 40.162882398828394\n",
      "Epoch 10 / 200 loss: 158.80183792114258\n",
      "MSE train 37.666465878456776 MSE test 39.0135216909417\n",
      "Epoch 11 / 200 loss: 153.41328048706055\n",
      "MSE train 36.59901170287452 MSE test 38.0197324795088\n",
      "Epoch 12 / 200 loss: 148.7431983947754\n",
      "MSE train 35.65642210875836 MSE test 37.14820245172196\n",
      "Epoch 13 / 200 loss: 144.64339065551758\n",
      "MSE train 34.81506123671794 MSE test 36.37426164233232\n",
      "Epoch 14 / 200 loss: 141.00763702392578\n",
      "MSE train 34.056026170527716 MSE test 35.67957711206102\n",
      "Epoch 15 / 200 loss: 137.7476806640625\n",
      "MSE train 33.365236573248744 MSE test 35.050694141984835\n",
      "Epoch 16 / 200 loss: 134.79551696777344\n",
      "MSE train 32.7287174932386 MSE test 34.4752167282683\n",
      "Epoch 17 / 200 loss: 132.09634399414062\n",
      "MSE train 32.135636809761 MSE test 33.94208655333427\n",
      "Epoch 18 / 200 loss: 129.59704399108887\n",
      "MSE train 31.579568962304922 MSE test 33.443715895163265\n",
      "Epoch 19 / 200 loss: 127.26154518127441\n",
      "MSE train 31.05415500870559 MSE test 32.97392936803888\n",
      "Epoch 20 / 200 loss: 125.06710243225098\n",
      "MSE train 30.555617977488833 MSE test 32.528108486147744\n",
      "Epoch 21 / 200 loss: 122.99006843566895\n",
      "MSE train 30.08238236925251 MSE test 32.10317946151015\n",
      "Epoch 22 / 200 loss: 121.01840209960938\n",
      "MSE train 29.63090761052809 MSE test 31.695818922644644\n",
      "Epoch 23 / 200 loss: 119.14375877380371\n",
      "MSE train 29.197330983318757 MSE test 31.302744016204425\n",
      "Epoch 24 / 200 loss: 117.3513355255127\n",
      "MSE train 28.779339080666034 MSE test 30.92190563717208\n",
      "Epoch 25 / 200 loss: 115.62743949890137\n",
      "MSE train 28.375190604168683 MSE test 30.552534793194503\n",
      "Epoch 26 / 200 loss: 113.96432304382324\n",
      "MSE train 27.982467202956055 MSE test 30.19374374587825\n",
      "Epoch 27 / 200 loss: 112.35430908203125\n",
      "MSE train 27.598724156944385 MSE test 29.844197671413006\n",
      "Epoch 28 / 200 loss: 110.78640747070312\n",
      "MSE train 27.222603815649126 MSE test 29.502672945484274\n",
      "Epoch 29 / 200 loss: 109.2514820098877\n",
      "MSE train 26.854529769954812 MSE test 29.168221692392954\n",
      "Epoch 30 / 200 loss: 107.74673843383789\n",
      "MSE train 26.495186209985036 MSE test 28.840613494635782\n",
      "Epoch 31 / 200 loss: 106.27641677856445\n",
      "MSE train 26.143210904898005 MSE test 28.519246664951005\n",
      "Epoch 32 / 200 loss: 104.83957862854004\n",
      "MSE train 25.798577002433593 MSE test 28.203727718057525\n",
      "Epoch 33 / 200 loss: 103.43217277526855\n",
      "MSE train 25.459509536172025 MSE test 27.89328721360544\n",
      "Epoch 34 / 200 loss: 102.0531120300293\n",
      "MSE train 25.12471875974717 MSE test 27.587318957751396\n",
      "Epoch 35 / 200 loss: 100.69442558288574\n",
      "MSE train 24.79441255711656 MSE test 27.285718092205286\n",
      "Epoch 36 / 200 loss: 99.35308265686035\n",
      "MSE train 24.46913236264419 MSE test 26.988360763131016\n",
      "Epoch 37 / 200 loss: 98.03030586242676\n",
      "MSE train 24.14918954401829 MSE test 26.695144893313707\n",
      "Epoch 38 / 200 loss: 96.72747039794922\n",
      "MSE train 23.834344126250837 MSE test 26.406034291135374\n",
      "Epoch 39 / 200 loss: 95.44489860534668\n",
      "MSE train 23.524248244034993 MSE test 26.121161761315996\n",
      "Epoch 40 / 200 loss: 94.18162727355957\n",
      "MSE train 23.218682468827016 MSE test 25.840613204404896\n",
      "Epoch 41 / 200 loss: 92.93706893920898\n",
      "MSE train 22.917826391313255 MSE test 25.564350287463704\n",
      "Epoch 42 / 200 loss: 91.7112045288086\n",
      "MSE train 22.622282763993123 MSE test 25.292503419947643\n",
      "Epoch 43 / 200 loss: 90.50539207458496\n",
      "MSE train 22.33225202542077 MSE test 25.025089826541734\n",
      "Epoch 44 / 200 loss: 89.32189559936523\n",
      "MSE train 22.04719870350018 MSE test 24.761708153355265\n",
      "Epoch 45 / 200 loss: 88.16046142578125\n",
      "MSE train 21.766626420060238 MSE test 24.501785851420077\n",
      "Epoch 46 / 200 loss: 87.01824760437012\n",
      "MSE train 21.490882359391506 MSE test 24.245141897659884\n",
      "Epoch 47 / 200 loss: 85.89418411254883\n",
      "MSE train 21.22014876285873 MSE test 23.991731155830852\n",
      "Epoch 48 / 200 loss: 84.79031181335449\n",
      "MSE train 20.954352369542285 MSE test 23.74139203515791\n",
      "Epoch 49 / 200 loss: 83.70700645446777\n",
      "MSE train 20.69316001128376 MSE test 23.49385528696126\n",
      "Epoch 50 / 200 loss: 82.64366912841797\n",
      "MSE train 20.43602843368783 MSE test 23.248780499282585\n",
      "Epoch 51 / 200 loss: 81.59872245788574\n",
      "MSE train 20.182423001049315 MSE test 23.005849428719927\n",
      "Epoch 52 / 200 loss: 80.56993675231934\n",
      "MSE train 19.932186039060298 MSE test 22.764895180835623\n",
      "Epoch 53 / 200 loss: 79.5554027557373\n",
      "MSE train 19.68571620987435 MSE test 22.526030316896573\n",
      "Epoch 54 / 200 loss: 78.55510330200195\n",
      "MSE train 19.443157528793655 MSE test 22.289243124324756\n",
      "Epoch 55 / 200 loss: 77.57059669494629\n",
      "MSE train 19.204006245717753 MSE test 22.053878757839342\n",
      "Epoch 56 / 200 loss: 76.60136032104492\n",
      "MSE train 18.96792754205283 MSE test 21.81942516164469\n",
      "Epoch 57 / 200 loss: 75.64500617980957\n",
      "MSE train 18.734784306726215 MSE test 21.58582590945088\n",
      "Epoch 58 / 200 loss: 74.70029640197754\n",
      "MSE train 18.50437437436747 MSE test 21.353263748669107\n",
      "Epoch 59 / 200 loss: 73.76652336120605\n",
      "MSE train 18.276498367024352 MSE test 21.122120268991615\n",
      "Epoch 60 / 200 loss: 72.84297370910645\n",
      "MSE train 18.05104115692159 MSE test 20.89289073223043\n",
      "Epoch 61 / 200 loss: 71.92916488647461\n",
      "MSE train 17.828259426987263 MSE test 20.666131850131936\n",
      "Epoch 62 / 200 loss: 71.02502632141113\n",
      "MSE train 17.60931030485614 MSE test 20.44256587257671\n",
      "Epoch 63 / 200 loss: 70.13291931152344\n",
      "MSE train 17.395216865014792 MSE test 20.222987161687758\n",
      "Epoch 64 / 200 loss: 69.25836944580078\n",
      "MSE train 17.185407537121304 MSE test 20.007551411160975\n",
      "Epoch 65 / 200 loss: 68.40378761291504\n",
      "MSE train 16.978921578065556 MSE test 19.79576954610557\n",
      "Epoch 66 / 200 loss: 67.56623268127441\n",
      "MSE train 16.77503649996093 MSE test 19.58700440528278\n",
      "Epoch 67 / 200 loss: 66.74195098876953\n",
      "MSE train 16.573137014657483 MSE test 19.38067645420367\n",
      "Epoch 68 / 200 loss: 65.92814254760742\n",
      "MSE train 16.372702388794362 MSE test 19.176292519001056\n",
      "Epoch 69 / 200 loss: 65.12245750427246\n",
      "MSE train 16.17332847785944 MSE test 18.973426645989264\n",
      "Epoch 70 / 200 loss: 64.32303142547607\n",
      "MSE train 15.974785055986557 MSE test 18.77177188218203\n",
      "Epoch 71 / 200 loss: 63.52827548980713\n",
      "MSE train 15.77733734757539 MSE test 18.57139603482784\n",
      "Epoch 72 / 200 loss: 62.73734474182129\n",
      "MSE train 15.581808671737031 MSE test 18.37269184115335\n",
      "Epoch 73 / 200 loss: 61.95182704925537\n",
      "MSE train 15.389038803999805 MSE test 18.17600541035376\n",
      "Epoch 74 / 200 loss: 61.175475120544434\n",
      "MSE train 15.199461938234686 MSE test 17.98156181153856\n",
      "Epoch 75 / 200 loss: 60.41119575500488\n",
      "MSE train 15.013276273767701 MSE test 17.789563334529277\n",
      "Epoch 76 / 200 loss: 59.66029644012451\n",
      "MSE train 14.830227646588968 MSE test 17.60008733372946\n",
      "Epoch 77 / 200 loss: 58.92280197143555\n",
      "MSE train 14.649806061928201 MSE test 17.41310286299613\n",
      "Epoch 78 / 200 loss: 58.19694519042969\n",
      "MSE train 14.471531284587341 MSE test 17.228615975710415\n",
      "Epoch 79 / 200 loss: 57.480417251586914\n",
      "MSE train 14.295150538437039 MSE test 17.046710055353337\n",
      "Epoch 80 / 200 loss: 56.77136421203613\n",
      "MSE train 14.12067071244791 MSE test 16.867429007147347\n",
      "Epoch 81 / 200 loss: 56.06901454925537\n",
      "MSE train 13.948277899936667 MSE test 16.690721360828075\n",
      "Epoch 82 / 200 loss: 55.37369632720947\n",
      "MSE train 13.778155645920549 MSE test 16.516506204043736\n",
      "Epoch 83 / 200 loss: 54.68627166748047\n",
      "MSE train 13.610504823565858 MSE test 16.344791287093557\n",
      "Epoch 84 / 200 loss: 54.00764846801758\n",
      "MSE train 13.445531011957987 MSE test 16.17567773420228\n",
      "Epoch 85 / 200 loss: 53.339003562927246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 13.283282561645464 MSE test 16.009164926403045\n",
      "Epoch 86 / 200 loss: 52.68117809295654\n",
      "MSE train 13.123648770389066 MSE test 15.845164044195277\n",
      "Epoch 87 / 200 loss: 52.0341796875\n",
      "MSE train 12.966517082794113 MSE test 15.683654919334026\n",
      "Epoch 88 / 200 loss: 51.39748477935791\n",
      "MSE train 12.811893650015275 MSE test 15.524749099204422\n",
      "Epoch 89 / 200 loss: 50.77082347869873\n",
      "MSE train 12.659799238307475 MSE test 15.368600173126678\n",
      "Epoch 90 / 200 loss: 50.15429973602295\n",
      "MSE train 12.510174642266781 MSE test 15.21531119883911\n",
      "Epoch 91 / 200 loss: 49.5479621887207\n",
      "MSE train 12.362916592013345 MSE test 15.064925840944651\n",
      "Epoch 92 / 200 loss: 48.951504707336426\n",
      "MSE train 12.217931085943686 MSE test 14.91744855062708\n",
      "Epoch 93 / 200 loss: 48.364545822143555\n",
      "MSE train 12.075152845288061 MSE test 14.772836509883255\n",
      "Epoch 94 / 200 loss: 47.786810874938965\n",
      "MSE train 11.934489560466295 MSE test 14.630966755713683\n",
      "Epoch 95 / 200 loss: 47.218079566955566\n",
      "MSE train 11.795756834696496 MSE test 14.491654188758718\n",
      "Epoch 96 / 200 loss: 46.65781021118164\n",
      "MSE train 11.65876103741986 MSE test 14.354733488522953\n",
      "Epoch 97 / 200 loss: 46.10505294799805\n",
      "MSE train 11.523414291456936 MSE test 14.220119133656233\n",
      "Epoch 98 / 200 loss: 45.55896759033203\n",
      "MSE train 11.389829812985955 MSE test 14.08781021957612\n",
      "Epoch 99 / 200 loss: 45.01930904388428\n",
      "MSE train 11.258329611332046 MSE test 13.957853697219736\n",
      "Epoch 100 / 200 loss: 44.486711502075195\n",
      "MSE train 11.129473454323302 MSE test 13.830348161912633\n",
      "Epoch 101 / 200 loss: 43.96264457702637\n",
      "MSE train 11.003787095369198 MSE test 13.705401346140077\n",
      "Epoch 102 / 200 loss: 43.44949150085449\n",
      "MSE train 10.88105538039453 MSE test 13.582865096702879\n",
      "Epoch 103 / 200 loss: 42.948659896850586\n",
      "MSE train 10.760742615652699 MSE test 13.462449483496947\n",
      "Epoch 104 / 200 loss: 42.45876407623291\n",
      "MSE train 10.642464812011019 MSE test 13.344015411761257\n",
      "Epoch 105 / 200 loss: 41.97780704498291\n",
      "MSE train 10.526133227645298 MSE test 13.22765911361958\n",
      "Epoch 106 / 200 loss: 41.50462245941162\n",
      "MSE train 10.41177986401384 MSE test 13.11345347574737\n",
      "Epoch 107 / 200 loss: 41.03922462463379\n",
      "MSE train 10.299417497303146 MSE test 13.00133620062155\n",
      "Epoch 108 / 200 loss: 40.58184337615967\n",
      "MSE train 10.188964119631091 MSE test 12.891245541628097\n",
      "Epoch 109 / 200 loss: 40.13248825073242\n",
      "MSE train 10.080134960245498 MSE test 12.783122766544606\n",
      "Epoch 110 / 200 loss: 39.69065284729004\n",
      "MSE train 9.972464009835813 MSE test 12.676905687238508\n",
      "Epoch 111 / 200 loss: 39.25490760803223\n",
      "MSE train 9.865460748422855 MSE test 12.57251035623873\n",
      "Epoch 112 / 200 loss: 38.82313251495361\n",
      "MSE train 9.758894196438114 MSE test 12.469684025425751\n",
      "Epoch 113 / 200 loss: 38.39346790313721\n",
      "MSE train 9.65277071669022 MSE test 12.367930665534036\n",
      "Epoch 114 / 200 loss: 37.96545219421387\n",
      "MSE train 9.547636956426853 MSE test 12.267020410884466\n",
      "Epoch 115 / 200 loss: 37.5397834777832\n",
      "MSE train 9.444665118110146 MSE test 12.16747747447863\n",
      "Epoch 116 / 200 loss: 37.11991786956787\n",
      "MSE train 9.344277428035776 MSE test 12.069667748165543\n",
      "Epoch 117 / 200 loss: 36.70988941192627\n",
      "MSE train 9.246323754409838 MSE test 11.973496873345319\n",
      "Epoch 118 / 200 loss: 36.310383796691895\n",
      "MSE train 9.150375791482027 MSE test 11.878688535819759\n",
      "Epoch 119 / 200 loss: 35.92046070098877\n",
      "MSE train 9.056102781639524 MSE test 11.78498255957064\n",
      "Epoch 120 / 200 loss: 35.53810214996338\n",
      "MSE train 8.963530099847734 MSE test 11.692308574046551\n",
      "Epoch 121 / 200 loss: 35.1625280380249\n",
      "MSE train 8.872333452341815 MSE test 11.60056280346934\n",
      "Epoch 122 / 200 loss: 34.79341506958008\n",
      "MSE train 8.782312352799487 MSE test 11.509650808198549\n",
      "Epoch 123 / 200 loss: 34.4291729927063\n",
      "MSE train 8.693737604632481 MSE test 11.419637021862899\n",
      "Epoch 124 / 200 loss: 34.069870471954346\n",
      "MSE train 8.6068334391343 MSE test 11.33063091277479\n",
      "Epoch 125 / 200 loss: 33.716957092285156\n",
      "MSE train 8.521496358464368 MSE test 11.242714246186571\n",
      "Epoch 126 / 200 loss: 33.37075471878052\n",
      "MSE train 8.437674105946412 MSE test 11.155998981727649\n",
      "Epoch 127 / 200 loss: 33.03060865402222\n",
      "MSE train 8.355394940839355 MSE test 11.070579637467212\n",
      "Epoch 128 / 200 loss: 32.6963586807251\n",
      "MSE train 8.274626946218323 MSE test 10.986440528444442\n",
      "Epoch 129 / 200 loss: 32.36808490753174\n",
      "MSE train 8.19521750994568 MSE test 10.903428350939514\n",
      "Epoch 130 / 200 loss: 32.04554891586304\n",
      "MSE train 8.116908502532361 MSE test 10.82130656927247\n",
      "Epoch 131 / 200 loss: 31.72800636291504\n",
      "MSE train 8.039528721318176 MSE test 10.739982387583453\n",
      "Epoch 132 / 200 loss: 31.41443967819214\n",
      "MSE train 7.9633869409654405 MSE test 10.659882285352637\n",
      "Epoch 133 / 200 loss: 31.104841709136963\n",
      "MSE train 7.888773644196124 MSE test 10.581495282710893\n",
      "Epoch 134 / 200 loss: 30.800944805145264\n",
      "MSE train 7.815546822159384 MSE test 10.5048432023128\n",
      "Epoch 135 / 200 loss: 30.50332546234131\n",
      "MSE train 7.74347541118596 MSE test 10.42968151333076\n",
      "Epoch 136 / 200 loss: 30.211187839508057\n",
      "MSE train 7.672430047044078 MSE test 10.355772312199596\n",
      "Epoch 137 / 200 loss: 29.923712730407715\n",
      "MSE train 7.602348567182217 MSE test 10.282928806896908\n",
      "Epoch 138 / 200 loss: 29.640498638153076\n",
      "MSE train 7.533183516507257 MSE test 10.211005008148797\n",
      "Epoch 139 / 200 loss: 29.36134624481201\n",
      "MSE train 7.464900983749376 MSE test 10.139922838163866\n",
      "Epoch 140 / 200 loss: 29.086061477661133\n",
      "MSE train 7.397531783616598 MSE test 10.069722420211864\n",
      "Epoch 141 / 200 loss: 28.814528465270996\n",
      "MSE train 7.331150444913449 MSE test 10.00052581731168\n",
      "Epoch 142 / 200 loss: 28.546892642974854\n",
      "MSE train 7.265739045821748 MSE test 9.932373634026165\n",
      "Epoch 143 / 200 loss: 28.283323764801025\n",
      "MSE train 7.2012313512024635 MSE test 9.86522726063157\n",
      "Epoch 144 / 200 loss: 28.02354669570923\n",
      "MSE train 7.137636746917007 MSE test 9.799093595265964\n",
      "Epoch 145 / 200 loss: 27.767241954803467\n",
      "MSE train 7.075038390454348 MSE test 9.734033403859994\n",
      "Epoch 146 / 200 loss: 27.514497756958008\n",
      "MSE train 7.013515618351351 MSE test 9.670097927504328\n",
      "Epoch 147 / 200 loss: 27.265664100646973\n",
      "MSE train 6.953081201820993 MSE test 9.607278974007265\n",
      "Epoch 148 / 200 loss: 27.021021366119385\n",
      "MSE train 6.893668918046414 MSE test 9.545499503977513\n",
      "Epoch 149 / 200 loss: 26.780575275421143\n",
      "MSE train 6.835158647773799 MSE test 9.484635119648184\n",
      "Epoch 150 / 200 loss: 26.544018268585205\n",
      "MSE train 6.777410665944908 MSE test 9.424548337320942\n",
      "Epoch 151 / 200 loss: 26.31085205078125\n",
      "MSE train 6.720297065197329 MSE test 9.365121551054921\n",
      "Epoch 152 / 200 loss: 26.08053731918335\n",
      "MSE train 6.663727247703246 MSE test 9.306283547411907\n",
      "Epoch 153 / 200 loss: 25.852595806121826\n",
      "MSE train 6.607657377365073 MSE test 9.248019438224052\n",
      "Epoch 154 / 200 loss: 25.626717567443848\n",
      "MSE train 6.5520760140091205 MSE test 9.190360935332206\n",
      "Epoch 155 / 200 loss: 25.402756214141846\n",
      "MSE train 6.4969805700482794 MSE test 9.133367179593339\n",
      "Epoch 156 / 200 loss: 25.18069553375244\n",
      "MSE train 6.442360505384455 MSE test 9.077108047182774\n",
      "Epoch 157 / 200 loss: 24.96053409576416\n",
      "MSE train 6.388194065451021 MSE test 9.021644511226214\n",
      "Epoch 158 / 200 loss: 24.74222421646118\n",
      "MSE train 6.334465499164424 MSE test 8.967014307396031\n",
      "Epoch 159 / 200 loss: 24.525670528411865\n",
      "MSE train 6.281185613424167 MSE test 8.913226900720222\n",
      "Epoch 160 / 200 loss: 24.31080722808838\n",
      "MSE train 6.22839558239807 MSE test 8.860264155914495\n",
      "Epoch 161 / 200 loss: 24.09768295288086\n",
      "MSE train 6.1761459886201 MSE test 8.808077502554111\n",
      "Epoch 162 / 200 loss: 23.886475563049316\n",
      "MSE train 6.124464812321861 MSE test 8.756583808998961\n",
      "Epoch 163 / 200 loss: 23.677404403686523\n",
      "MSE train 6.073334000604178 MSE test 8.705668449935368\n",
      "Epoch 164 / 200 loss: 23.470587730407715\n",
      "MSE train 6.022692474026836 MSE test 8.655196440215883\n",
      "Epoch 165 / 200 loss: 23.265952110290527\n",
      "MSE train 5.972482857281524 MSE test 8.605041673743822\n",
      "Epoch 166 / 200 loss: 23.06326961517334\n",
      "MSE train 5.922731009060978 MSE test 8.5551416349478\n",
      "Epoch 167 / 200 loss: 22.862377643585205\n",
      "MSE train 5.873584548455194 MSE test 8.50555243396661\n",
      "Epoch 168 / 200 loss: 22.663496017456055\n",
      "MSE train 5.8252232513660305 MSE test 8.456402913913172\n",
      "Epoch 169 / 200 loss: 22.46730136871338\n",
      "MSE train 5.777724527281224 MSE test 8.407763137375703\n",
      "Epoch 170 / 200 loss: 22.274456024169922\n",
      "MSE train 5.73104562165594 MSE test 8.359627409092951\n",
      "Epoch 171 / 200 loss: 22.085137844085693\n",
      "MSE train 5.68509196899801 MSE test 8.311964330456465\n",
      "Epoch 172 / 200 loss: 21.89908790588379\n",
      "MSE train 5.639786931437801 MSE test 8.264758972076082\n",
      "Epoch 173 / 200 loss: 21.715913772583008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.595101437313499 MSE test 8.21803770953921\n",
      "Epoch 174 / 200 loss: 21.53531312942505\n",
      "MSE train 5.551058119451032 MSE test 8.171859928014547\n",
      "Epoch 175 / 200 loss: 21.35715961456299\n",
      "MSE train 5.507711777907041 MSE test 8.126277190492733\n",
      "Epoch 176 / 200 loss: 21.181525707244873\n",
      "MSE train 5.46506697193629 MSE test 8.081298714624003\n",
      "Epoch 177 / 200 loss: 21.00864267349243\n",
      "MSE train 5.423027701443615 MSE test 8.036888156696826\n",
      "Epoch 178 / 200 loss: 20.838512420654297\n",
      "MSE train 5.381471418589931 MSE test 7.993000854081835\n",
      "Epoch 179 / 200 loss: 20.67074966430664\n",
      "MSE train 5.340311329988758 MSE test 7.94961247967766\n",
      "Epoch 180 / 200 loss: 20.504913330078125\n",
      "MSE train 5.299500629874961 MSE test 7.906715363452576\n",
      "Epoch 181 / 200 loss: 20.340735912322998\n",
      "MSE train 5.259002201334662 MSE test 7.8643018496424135\n",
      "Epoch 182 / 200 loss: 20.17808198928833\n",
      "MSE train 5.218757646855353 MSE test 7.822359361064428\n",
      "Epoch 183 / 200 loss: 20.016815185546875\n",
      "MSE train 5.178695944567854 MSE test 7.780889248283175\n",
      "Epoch 184 / 200 loss: 19.856698036193848\n",
      "MSE train 5.138815489634606 MSE test 7.739947206580711\n",
      "Epoch 185 / 200 loss: 19.69748544692993\n",
      "MSE train 5.099375806430687 MSE test 7.699684240339062\n",
      "Epoch 186 / 200 loss: 19.539331436157227\n",
      "MSE train 5.060837193946904 MSE test 7.660286327211169\n",
      "Epoch 187 / 200 loss: 19.38349723815918\n",
      "MSE train 5.023329617739015 MSE test 7.621785017426084\n",
      "Epoch 188 / 200 loss: 19.231616973876953\n",
      "MSE train 4.9867240148967245 MSE test 7.584112913316823\n",
      "Epoch 189 / 200 loss: 19.083850860595703\n",
      "MSE train 4.950884494953536 MSE test 7.547213868429963\n",
      "Epoch 190 / 200 loss: 18.939565181732178\n",
      "MSE train 4.915696733432314 MSE test 7.511047063252526\n",
      "Epoch 191 / 200 loss: 18.79820203781128\n",
      "MSE train 4.881062163836249 MSE test 7.4755755067124365\n",
      "Epoch 192 / 200 loss: 18.659307956695557\n",
      "MSE train 4.846892173596139 MSE test 7.440754179401584\n",
      "Epoch 193 / 200 loss: 18.5225248336792\n",
      "MSE train 4.813114222771523 MSE test 7.406528551588843\n",
      "Epoch 194 / 200 loss: 18.38756227493286\n",
      "MSE train 4.779719820943353 MSE test 7.372846928256549\n",
      "Epoch 195 / 200 loss: 18.25424575805664\n",
      "MSE train 4.746814307614442 MSE test 7.339684057000823\n",
      "Epoch 196 / 200 loss: 18.122732639312744\n",
      "MSE train 4.71450825709714 MSE test 7.307031881183467\n",
      "Epoch 197 / 200 loss: 17.9935245513916\n",
      "MSE train 4.68276765508251 MSE test 7.274859044070459\n",
      "Epoch 198 / 200 loss: 17.86687421798706\n",
      "MSE train 4.651474299398784 MSE test 7.243109462062174\n",
      "Epoch 199 / 200 loss: 17.742450714111328\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(hm_epochs):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i in range(int(tot_images/batch_size)):\n",
    "        epoch_x = X_train[ i*batch_size : (i+1)*batch_size ]\n",
    "        _, c = sess.run([optimizer, meansq],\\\n",
    "               feed_dict={input_layer: epoch_x, \\\n",
    "               output_true: epoch_x})\n",
    "        epoch_loss += c\n",
    "        \n",
    "    output_train = sess.run(output_layer,\\\n",
    "               feed_dict={input_layer:X_train})\n",
    "    output_test = sess.run(output_layer,\\\n",
    "                   feed_dict={input_layer:X_test})\n",
    "        \n",
    "    print('MSE train', MSE(output_train, X_train),'MSE test', MSE(output_test, X_test))      \n",
    "    print('Epoch', epoch, '/', hm_epochs, 'loss:',epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = pd.DataFrame()\n",
    "preds = sess.run(output_layer, feed_dict={input_layer: user_movie_matrix})\n",
    "pred_data = pred_data.append(pd.DataFrame(preds))\n",
    "pred_data = pred_data.stack().reset_index(name='rating')\n",
    "pred_data.columns = ['userId', 'title', 'rating']\n",
    "users = user_movie_matrix.index.tolist()\n",
    "movies = user_movie_matrix.columns.tolist()\n",
    "pred_data['userId'] = pred_data['userId'].map(lambda value: users[value])\n",
    "pred_data['title'] = pred_data['title'].map(lambda value: movies[value])\n",
    "keys = ['userId', 'title']\n",
    "index_1 = pred_data.set_index(keys).index\n",
    "index_2 = ur20plus.set_index(keys).index\n",
    "top_ten_ranked = pred_data[~index_1.isin(index_2)]\n",
    "top_ten_ranked = top_ten_ranked.sort_values(['userId', 'rating'], ascending=[True, False])\n",
    "top_ten_ranked = top_ten_ranked.groupby('userId').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>735134</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Simple Plan, A (1998)</td>\n",
       "      <td>7.316847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735371</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Witness (1985)</td>\n",
       "      <td>7.061924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734766</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Leaving Las Vegas (1995)</td>\n",
       "      <td>7.045127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735301</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Tropic Thunder (2008)</td>\n",
       "      <td>6.941782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734854</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Mighty Aphrodite (1995)</td>\n",
       "      <td>6.583347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734103</th>\n",
       "      <td>9999999</td>\n",
       "      <td>10 Things I Hate About You (1999)</td>\n",
       "      <td>6.565654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734985</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Planet of the Apes (1968)</td>\n",
       "      <td>6.465528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734708</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Island of Dr. Moreau, The (1996)</td>\n",
       "      <td>6.461706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735285</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Top Gun (1986)</td>\n",
       "      <td>6.397721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734233</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Better Off Dead... (1985)</td>\n",
       "      <td>6.371764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId                              title    rating\n",
       "735134  9999999              Simple Plan, A (1998)  7.316847\n",
       "735371  9999999                     Witness (1985)  7.061924\n",
       "734766  9999999           Leaving Las Vegas (1995)  7.045127\n",
       "735301  9999999              Tropic Thunder (2008)  6.941782\n",
       "734854  9999999            Mighty Aphrodite (1995)  6.583347\n",
       "734103  9999999  10 Things I Hate About You (1999)  6.565654\n",
       "734985  9999999          Planet of the Apes (1968)  6.465528\n",
       "734708  9999999   Island of Dr. Moreau, The (1996)  6.461706\n",
       "735285  9999999                     Top Gun (1986)  6.397721\n",
       "734233  9999999          Better Off Dead... (1985)  6.371764"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_ranked.loc[top_ten_ranked['userId'] == 9999999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus = ur20plus.append(pd.DataFrame([[\"Hulk (2003)\",1,9999991,4370,5,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)\n",
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float)\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "ur20plus['rating'] = rating_scaled\n",
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title'])\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "user_movie_matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = pd.DataFrame()\n",
    "preds = sess.run(output_layer, feed_dict={input_layer: user_movie_matrix})\n",
    "pred_data = pred_data.append(pd.DataFrame(preds))\n",
    "pred_data = pred_data.stack().reset_index(name='rating')\n",
    "pred_data.columns = ['userId', 'title', 'rating']\n",
    "users = user_movie_matrix.index.tolist()\n",
    "movies = user_movie_matrix.columns.tolist()\n",
    "pred_data['userId'] = pred_data['userId'].map(lambda value: users[value])\n",
    "pred_data['title'] = pred_data['title'].map(lambda value: movies[value])\n",
    "keys = ['userId', 'title']\n",
    "index_1 = pred_data.set_index(keys).index\n",
    "index_2 = ur20plus.set_index(keys).index\n",
    "top_ten_ranked = pred_data[~index_1.isin(index_2)]\n",
    "top_ten_ranked = top_ten_ranked.sort_values(['userId', 'rating'], ascending=[True, False])\n",
    "top_ten_ranked = top_ten_ranked.groupby('userId').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>734950</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Outbreak (1995)</td>\n",
       "      <td>7.819874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734502</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Fast and the Furious, The (2001)</td>\n",
       "      <td>7.736551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734310</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Cape Fear (1991)</td>\n",
       "      <td>7.396494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734341</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Cinderella (1950)</td>\n",
       "      <td>7.045932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734110</th>\n",
       "      <td>9999991</td>\n",
       "      <td>2001: A Space Odyssey (1968)</td>\n",
       "      <td>6.947413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734125</th>\n",
       "      <td>9999991</td>\n",
       "      <td>A.I. Artificial Intelligence (2001)</td>\n",
       "      <td>6.777423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735383</th>\n",
       "      <td>9999991</td>\n",
       "      <td>X-Men: Days of Future Past (2014)</td>\n",
       "      <td>6.678552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734673</th>\n",
       "      <td>9999991</td>\n",
       "      <td>I Heart Huckabees (2004)</td>\n",
       "      <td>6.576962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734901</th>\n",
       "      <td>9999991</td>\n",
       "      <td>My Fair Lady (1964)</td>\n",
       "      <td>6.494349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734207</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Backdraft (1991)</td>\n",
       "      <td>6.404796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId                                title    rating\n",
       "734950  9999991                      Outbreak (1995)  7.819874\n",
       "734502  9999991     Fast and the Furious, The (2001)  7.736551\n",
       "734310  9999991                     Cape Fear (1991)  7.396494\n",
       "734341  9999991                    Cinderella (1950)  7.045932\n",
       "734110  9999991         2001: A Space Odyssey (1968)  6.947413\n",
       "734125  9999991  A.I. Artificial Intelligence (2001)  6.777423\n",
       "735383  9999991    X-Men: Days of Future Past (2014)  6.678552\n",
       "734673  9999991             I Heart Huckabees (2004)  6.576962\n",
       "734901  9999991                  My Fair Lady (1964)  6.494349\n",
       "734207  9999991                     Backdraft (1991)  6.404796"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_ranked.loc[top_ten_ranked['userId'] == 9999991] #an example of the top 10 recommendations for the above\n",
    "# new user who only rated one movie, i.e., \"Hulk (2003)\", with a 5/5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus = ur20plus.append(pd.DataFrame([[\"Hulk (2003)\",1,9999992,4370,5,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)\n",
    "ur20plus = ur20plus.append(pd.DataFrame([[\"Aliens (1986)\",1,9999992,4370,3,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)\n",
    "ur20plus = ur20plus.append(pd.DataFrame([[\"Brave (2012)\",1,9999992,4370,4,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)\n",
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float)\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "ur20plus['rating'] = rating_scaled\n",
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title'])\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "user_movie_matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = pd.DataFrame()\n",
    "preds = sess.run(output_layer, feed_dict={input_layer: user_movie_matrix})\n",
    "pred_data = pred_data.append(pd.DataFrame(preds))\n",
    "pred_data = pred_data.stack().reset_index(name='rating')\n",
    "pred_data.columns = ['userId', 'title', 'rating']\n",
    "users = user_movie_matrix.index.tolist()\n",
    "movies = user_movie_matrix.columns.tolist()\n",
    "pred_data['userId'] = pred_data['userId'].map(lambda value: users[value])\n",
    "pred_data['title'] = pred_data['title'].map(lambda value: movies[value])\n",
    "keys = ['userId', 'title']\n",
    "index_1 = pred_data.set_index(keys).index\n",
    "index_2 = ur20plus.set_index(keys).index\n",
    "top_ten_ranked = pred_data[~index_1.isin(index_2)]\n",
    "top_ten_ranked = top_ten_ranked.sort_values(['userId', 'rating'], ascending=[True, False])\n",
    "top_ten_ranked = top_ten_ranked.groupby('userId').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>735422</th>\n",
       "      <td>9999992</td>\n",
       "      <td>A.I. Artificial Intelligence (2001)</td>\n",
       "      <td>10.394133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735799</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Fast and the Furious, The (2001)</td>\n",
       "      <td>10.382468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736247</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Outbreak (1995)</td>\n",
       "      <td>9.191101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736059</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Lawnmower Man, The (1992)</td>\n",
       "      <td>8.967257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736390</th>\n",
       "      <td>9999992</td>\n",
       "      <td>School of Rock (2003)</td>\n",
       "      <td>8.936007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736358</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Rogue One: A Star Wars Story (2016)</td>\n",
       "      <td>8.628779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735880</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Goldfinger (1964)</td>\n",
       "      <td>8.338116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736063</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Leaving Las Vegas (1995)</td>\n",
       "      <td>8.093570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736151</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Mighty Aphrodite (1995)</td>\n",
       "      <td>8.018227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735561</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Blue Velvet (1986)</td>\n",
       "      <td>7.955853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId                                title     rating\n",
       "735422  9999992  A.I. Artificial Intelligence (2001)  10.394133\n",
       "735799  9999992     Fast and the Furious, The (2001)  10.382468\n",
       "736247  9999992                      Outbreak (1995)   9.191101\n",
       "736059  9999992            Lawnmower Man, The (1992)   8.967257\n",
       "736390  9999992                School of Rock (2003)   8.936007\n",
       "736358  9999992  Rogue One: A Star Wars Story (2016)   8.628779\n",
       "735880  9999992                    Goldfinger (1964)   8.338116\n",
       "736063  9999992             Leaving Las Vegas (1995)   8.093570\n",
       "736151  9999992              Mighty Aphrodite (1995)   8.018227\n",
       "735561  9999992                   Blue Velvet (1986)   7.955853"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_ranked.loc[top_ten_ranked['userId'] == 9999992] #an example of the top 10 recommendations for the above\n",
    "# new user who rated three movies, i.e., \"Hulk (2003)\" with a 5/5, \"Aliens (1986)\" with a 3/5, and \"Brave (2012)\"\n",
    "# with a 4/5."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
