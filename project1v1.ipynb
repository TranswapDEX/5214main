{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used code from this tutorial:\n",
    "# https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Collaborative%20Filtering%20Model%20with%20TensorFlow.ipynb\n",
    "# And we also used code from this tutorial:\n",
    "# https://medium.com/@connectwithghosh/recommender-system-on-the-movielens-using-an-autoencoder-using-tensorflow-in-python-f13d3e8d600d\n",
    "# Then, we integrated these two tutorials and edited the code from each of them in order to create a recommender that allows us to recommend a top 10 list of movies without needing to retrain for each new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.read_csv('/Users/blakemyers/Desktop/data/ratings.csv', error_bad_lines=False, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv(\"/Users/blakemyers/Desktop/data/movies.csv\", error_bad_lines=False, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating = pd.merge(rating, movie, on = 'movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie = movie_rating.groupby(\"title\")[\"rating\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie.rename({\"rating\": \"ratecount_movie\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie = numrate_movie.query(\"ratecount_movie >= 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings20plus = pd.merge(numrate_movie, movie_rating, on = 'title', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user = ratings20plus.groupby(\"userId\")[\"rating\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user.rename({\"rating\": \"ratecount_user\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user = numrate_user.query(\"ratecount_user >= 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus = pd.merge(ratings20plus, numrate_user, on = \"userId\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus = ur20plus.append(pd.DataFrame([[\"A.I. Artificial Intelligence (2001)\",1,9999999,4370,5,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float)\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "ur20plus['rating'] = rating_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title'])\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "user_movie_matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>(500) Days of Summer (2009)</th>\n",
       "      <th>10 Things I Hate About You (1999)</th>\n",
       "      <th>101 Dalmatians (1996)</th>\n",
       "      <th>101 Dalmatians (One Hundred and One Dalmatians) (1961)</th>\n",
       "      <th>12 Angry Men (1957)</th>\n",
       "      <th>13 Going on 30 (2004)</th>\n",
       "      <th>13th Warrior, The (1999)</th>\n",
       "      <th>1408 (2007)</th>\n",
       "      <th>2001: A Space Odyssey (1968)</th>\n",
       "      <th>2012 (2009)</th>\n",
       "      <th>...</th>\n",
       "      <th>Young Frankenstein (1974)</th>\n",
       "      <th>Young Guns (1988)</th>\n",
       "      <th>Zack and Miri Make a Porno (2008)</th>\n",
       "      <th>Zodiac (2007)</th>\n",
       "      <th>Zombieland (2009)</th>\n",
       "      <th>Zoolander (2001)</th>\n",
       "      <th>Zootopia (2016)</th>\n",
       "      <th>eXistenZ (1999)</th>\n",
       "      <th>xXx (2002)</th>\n",
       "      <th>Â¡Three Amigos! (1986)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "title   (500) Days of Summer (2009)  10 Things I Hate About You (1999)  \\\n",
       "userId                                                                   \n",
       "1                               0.0                                0.0   \n",
       "2                               0.0                                0.0   \n",
       "3                               0.0                                0.0   \n",
       "4                               0.0                                0.0   \n",
       "5                               0.0                                0.0   \n",
       "\n",
       "title   101 Dalmatians (1996)  \\\n",
       "userId                          \n",
       "1                         0.0   \n",
       "2                         0.0   \n",
       "3                         0.0   \n",
       "4                         0.0   \n",
       "5                         0.0   \n",
       "\n",
       "title   101 Dalmatians (One Hundred and One Dalmatians) (1961)  \\\n",
       "userId                                                           \n",
       "1                                                     0.0        \n",
       "2                                                     0.0        \n",
       "3                                                     0.0        \n",
       "4                                                     0.0        \n",
       "5                                                     0.0        \n",
       "\n",
       "title   12 Angry Men (1957)  13 Going on 30 (2004)  13th Warrior, The (1999)  \\\n",
       "userId                                                                         \n",
       "1                       0.0                    0.0                  0.777778   \n",
       "2                       0.0                    0.0                  0.000000   \n",
       "3                       0.0                    0.0                  0.000000   \n",
       "4                       1.0                    0.0                  0.000000   \n",
       "5                       0.0                    0.0                  0.000000   \n",
       "\n",
       "title   1408 (2007)  2001: A Space Odyssey (1968)  2012 (2009)  ...  \\\n",
       "userId                                                          ...   \n",
       "1               0.0                           0.0          0.0  ...   \n",
       "2               0.0                           0.0          0.0  ...   \n",
       "3               0.0                           0.0          0.0  ...   \n",
       "4               0.0                           0.0          0.0  ...   \n",
       "5               0.0                           0.0          0.0  ...   \n",
       "\n",
       "title   Young Frankenstein (1974)  Young Guns (1988)  \\\n",
       "userId                                                 \n",
       "1                             1.0                0.0   \n",
       "2                             0.0                0.0   \n",
       "3                             0.0                0.0   \n",
       "4                             0.0                0.0   \n",
       "5                             0.0                0.0   \n",
       "\n",
       "title   Zack and Miri Make a Porno (2008)  Zodiac (2007)  Zombieland (2009)  \\\n",
       "userId                                                                        \n",
       "1                                     0.0            0.0           0.000000   \n",
       "2                                     0.0            0.0           0.555556   \n",
       "3                                     0.0            0.0           0.000000   \n",
       "4                                     0.0            0.0           0.000000   \n",
       "5                                     0.0            0.0           0.000000   \n",
       "\n",
       "title   Zoolander (2001)  Zootopia (2016)  eXistenZ (1999)  xXx (2002)  \\\n",
       "userId                                                                   \n",
       "1                    0.0              0.0              0.0         0.0   \n",
       "2                    0.0              0.0              0.0         0.0   \n",
       "3                    0.0              0.0              0.0         0.0   \n",
       "4                    0.0              0.0              0.0         0.0   \n",
       "5                    0.0              0.0              0.0         0.0   \n",
       "\n",
       "title   Â¡Three Amigos! (1986)  \n",
       "userId                          \n",
       "1                     0.777778  \n",
       "2                     0.000000  \n",
       "3                     0.000000  \n",
       "4                     0.000000  \n",
       "5                     0.000000  \n",
       "\n",
       "[5 rows x 1297 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_movie_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(user_movie_matrix, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/blakemyers/opt/anaconda3/envs/tf_environment/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = ur20plus['title'].nunique()\n",
    "n_nodes_inpl = num_input  \n",
    "n_nodes_hl1  = 256  \n",
    "n_nodes_outl = num_input  \n",
    "hidden_1_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_inpl+1,n_nodes_hl1]))}\n",
    "output_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1+1,n_nodes_outl]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/blakemyers/opt/anaconda3/envs/tf_environment/lib/python3.7/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.placeholder('float', [None, num_input])\n",
    "input_layer_const = tf.fill( [tf.shape(input_layer)[0], 1] ,1.0  )\n",
    "input_layer_concat =  tf.concat([input_layer, input_layer_const], 1)\n",
    "layer_1 = tf.nn.sigmoid(tf.matmul(input_layer_concat,hidden_1_layer_vals['weights']))\n",
    "layer1_const = tf.fill( [tf.shape(layer_1)[0], 1] ,1.0  )\n",
    "layer_concat =  tf.concat([layer_1, layer1_const], 1)\n",
    "output_layer = tf.matmul( layer_concat,output_layer_vals['weights'])\n",
    "output_true = tf.placeholder('float', [None, num_input])\n",
    "meansq =    tf.reduce_mean(tf.square(output_layer - output_true))\n",
    "learn_rate = 0.1\n",
    "optimizer = tf.train.AdagradOptimizer(learn_rate).minimize(meansq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "batch_size = 100\n",
    "hm_epochs =200\n",
    "tot_images = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 87.14590365887507 MSE test 88.89720264489704\n",
      "Epoch 0 / 200 loss: 402.74925994873047\n",
      "MSE train 72.87188677151673 MSE test 74.65397533155947\n",
      "Epoch 1 / 200 loss: 324.65380859375\n",
      "MSE train 63.374221012655966 MSE test 65.20928233860539\n",
      "Epoch 2 / 200 loss: 275.6084518432617\n",
      "MSE train 56.70541653532451 MSE test 58.59570008118859\n",
      "Epoch 3 / 200 loss: 242.34528732299805\n",
      "MSE train 51.823586804881366 MSE test 53.73769278739335\n",
      "Epoch 4 / 200 loss: 218.63084411621094\n",
      "MSE train 48.11270792537035 MSE test 50.044162212087286\n",
      "Epoch 5 / 200 loss: 201.04117965698242\n",
      "MSE train 45.193681947029965 MSE test 47.1491398282726\n",
      "Epoch 6 / 200 loss: 187.49439239501953\n",
      "MSE train 42.8586923176389 MSE test 44.83127947136522\n",
      "Epoch 7 / 200 loss: 176.76210403442383\n",
      "MSE train 40.95200999349856 MSE test 42.93942922996855\n",
      "Epoch 8 / 200 loss: 168.11508560180664\n",
      "MSE train 39.367306011441265 MSE test 41.370400206278454\n",
      "Epoch 9 / 200 loss: 161.0049934387207\n",
      "MSE train 38.026129038473286 MSE test 40.04796910011531\n",
      "Epoch 10 / 200 loss: 155.0551528930664\n",
      "MSE train 36.87190313970675 MSE test 38.91547447550678\n",
      "Epoch 11 / 200 loss: 149.9843864440918\n",
      "MSE train 35.86433430336148 MSE test 37.930273532536745\n",
      "Epoch 12 / 200 loss: 145.59050750732422\n",
      "MSE train 34.97428199811707 MSE test 37.0624190975253\n",
      "Epoch 13 / 200 loss: 141.73381423950195\n",
      "MSE train 34.17900667091557 MSE test 36.29002303342607\n",
      "Epoch 14 / 200 loss: 138.31175231933594\n",
      "MSE train 33.46159251786591 MSE test 35.59429035518721\n",
      "Epoch 15 / 200 loss: 135.2423973083496\n",
      "MSE train 32.80790088649414 MSE test 34.96100365272468\n",
      "Epoch 16 / 200 loss: 132.46285247802734\n",
      "MSE train 32.205390082466984 MSE test 34.380107467579535\n",
      "Epoch 17 / 200 loss: 129.9196071624756\n",
      "MSE train 31.643470552469182 MSE test 33.84318662309283\n",
      "Epoch 18 / 200 loss: 127.56589698791504\n",
      "MSE train 31.113835856265005 MSE test 33.34175063995838\n",
      "Epoch 19 / 200 loss: 125.36236763000488\n",
      "MSE train 30.610962047492627 MSE test 32.867904954802604\n",
      "Epoch 20 / 200 loss: 123.27870750427246\n",
      "MSE train 30.13207166942197 MSE test 32.41583236868022\n",
      "Epoch 21 / 200 loss: 121.29661178588867\n",
      "MSE train 29.674059546865745 MSE test 31.981535573365854\n",
      "Epoch 22 / 200 loss: 119.40589141845703\n",
      "MSE train 29.233494119323794 MSE test 31.562199831415736\n",
      "Epoch 23 / 200 loss: 117.59321212768555\n",
      "MSE train 28.806635630727037 MSE test 31.155580592196202\n",
      "Epoch 24 / 200 loss: 115.84417724609375\n",
      "MSE train 28.39037883879971 MSE test 30.76033272757145\n",
      "Epoch 25 / 200 loss: 114.14432716369629\n",
      "MSE train 27.983195038228793 MSE test 30.37476654628219\n",
      "Epoch 26 / 200 loss: 112.48346519470215\n",
      "MSE train 27.584668495068797 MSE test 29.997555095072528\n",
      "Epoch 27 / 200 loss: 110.85716438293457\n",
      "MSE train 27.194380486045077 MSE test 29.62797997590575\n",
      "Epoch 28 / 200 loss: 109.26372528076172\n",
      "MSE train 26.81250144477648 MSE test 29.264862610875447\n",
      "Epoch 29 / 200 loss: 107.70180702209473\n",
      "MSE train 26.43944247708062 MSE test 28.907347200816574\n",
      "Epoch 30 / 200 loss: 106.17271995544434\n",
      "MSE train 26.075435139451 MSE test 28.555512450173694\n",
      "Epoch 31 / 200 loss: 104.67887878417969\n",
      "MSE train 25.720456597037295 MSE test 28.209818738448977\n",
      "Epoch 32 / 200 loss: 103.22237586975098\n",
      "MSE train 25.373868523246298 MSE test 27.870367687466853\n",
      "Epoch 33 / 200 loss: 101.8025951385498\n",
      "MSE train 25.034892946087865 MSE test 27.536944611123786\n",
      "Epoch 34 / 200 loss: 100.41630363464355\n",
      "MSE train 24.703028050917624 MSE test 27.209384302774804\n",
      "Epoch 35 / 200 loss: 99.06048011779785\n",
      "MSE train 24.37808091577569 MSE test 26.88777217422242\n",
      "Epoch 36 / 200 loss: 97.73367881774902\n",
      "MSE train 24.05981332732637 MSE test 26.572428714117226\n",
      "Epoch 37 / 200 loss: 96.43537139892578\n",
      "MSE train 23.74761748134085 MSE test 26.263388397866255\n",
      "Epoch 38 / 200 loss: 95.16417694091797\n",
      "MSE train 23.440609361875424 MSE test 25.95985559089866\n",
      "Epoch 39 / 200 loss: 93.91703414916992\n",
      "MSE train 23.13802723645502 MSE test 25.66072071464082\n",
      "Epoch 40 / 200 loss: 92.69014358520508\n",
      "MSE train 22.839373885300184 MSE test 25.365276012191742\n",
      "Epoch 41 / 200 loss: 91.48071670532227\n",
      "MSE train 22.544364332526605 MSE test 25.073257904498565\n",
      "Epoch 42 / 200 loss: 90.28729820251465\n",
      "MSE train 22.25284711204297 MSE test 24.78489536291385\n",
      "Epoch 43 / 200 loss: 89.10934066772461\n",
      "MSE train 21.964821557806122 MSE test 24.50086761015794\n",
      "Epoch 44 / 200 loss: 87.94664192199707\n",
      "MSE train 21.680349543166145 MSE test 24.221139353102014\n",
      "Epoch 45 / 200 loss: 86.79942512512207\n",
      "MSE train 21.399279412980366 MSE test 23.94499641915962\n",
      "Epoch 46 / 200 loss: 85.66775131225586\n",
      "MSE train 21.121473568891716 MSE test 23.671820661668725\n",
      "Epoch 47 / 200 loss: 84.55048561096191\n",
      "MSE train 20.847201201377143 MSE test 23.401329798088092\n",
      "Epoch 48 / 200 loss: 83.44698715209961\n",
      "MSE train 20.576949399770378 MSE test 23.133585025879505\n",
      "Epoch 49 / 200 loss: 82.35835075378418\n",
      "MSE train 20.311045451622228 MSE test 22.868843775089402\n",
      "Epoch 50 / 200 loss: 81.28636932373047\n",
      "MSE train 20.049543018233102 MSE test 22.60736768949738\n",
      "Epoch 51 / 200 loss: 80.2324390411377\n",
      "MSE train 19.792288243581066 MSE test 22.349283361929395\n",
      "Epoch 52 / 200 loss: 79.19673919677734\n",
      "MSE train 19.53908403190542 MSE test 22.09459409440345\n",
      "Epoch 53 / 200 loss: 78.1783618927002\n",
      "MSE train 19.29008748248813 MSE test 21.843458622187924\n",
      "Epoch 54 / 200 loss: 77.1761531829834\n",
      "MSE train 19.045751750904827 MSE test 21.5964405044891\n",
      "Epoch 55 / 200 loss: 76.1903190612793\n",
      "MSE train 18.806036281878544 MSE test 21.35415500019996\n",
      "Epoch 56 / 200 loss: 75.22207069396973\n",
      "MSE train 18.57049345057149 MSE test 21.116618613629782\n",
      "Epoch 57 / 200 loss: 74.27135276794434\n",
      "MSE train 18.338850267311358 MSE test 20.88353847139733\n",
      "Epoch 58 / 200 loss: 73.3369312286377\n",
      "MSE train 18.110854475847287 MSE test 20.65486140098716\n",
      "Epoch 59 / 200 loss: 72.4179744720459\n",
      "MSE train 17.88601292404645 MSE test 20.430602114504566\n",
      "Epoch 60 / 200 loss: 71.51323127746582\n",
      "MSE train 17.663943515113296 MSE test 20.21037892985758\n",
      "Epoch 61 / 200 loss: 70.62045097351074\n",
      "MSE train 17.445029867319807 MSE test 19.993769267285373\n",
      "Epoch 62 / 200 loss: 69.73845672607422\n",
      "MSE train 17.23039842260333 MSE test 19.780806975065722\n",
      "Epoch 63 / 200 loss: 68.86977005004883\n",
      "MSE train 17.020623260156775 MSE test 19.571578390028463\n",
      "Epoch 64 / 200 loss: 68.01925277709961\n",
      "MSE train 16.815552412491616 MSE test 19.36590142023432\n",
      "Epoch 65 / 200 loss: 67.18840408325195\n",
      "MSE train 16.6149801375373 MSE test 19.16358291199012\n",
      "Epoch 66 / 200 loss: 66.37615203857422\n",
      "MSE train 16.41841553408036 MSE test 18.96455924987343\n",
      "Epoch 67 / 200 loss: 65.58118343353271\n",
      "MSE train 16.2251514496897 MSE test 18.7689666646321\n",
      "Epoch 68 / 200 loss: 64.80109024047852\n",
      "MSE train 16.03462697065838 MSE test 18.576802052749315\n",
      "Epoch 69 / 200 loss: 64.03303623199463\n",
      "MSE train 15.84663365656336 MSE test 18.387584656778415\n",
      "Epoch 70 / 200 loss: 63.275146484375\n",
      "MSE train 15.661266171960193 MSE test 18.200850973644997\n",
      "Epoch 71 / 200 loss: 62.52716541290283\n",
      "MSE train 15.478747446886226 MSE test 18.016506732835833\n",
      "Epoch 72 / 200 loss: 61.78995132446289\n",
      "MSE train 15.299342613657343 MSE test 17.83467314742361\n",
      "Epoch 73 / 200 loss: 61.06454944610596\n",
      "MSE train 15.123381190695778 MSE test 17.655536745025955\n",
      "Epoch 74 / 200 loss: 60.35197353363037\n",
      "MSE train 14.951187707232945 MSE test 17.47929458984167\n",
      "Epoch 75 / 200 loss: 59.65345287322998\n",
      "MSE train 14.78280731984993 MSE test 17.30600658135402\n",
      "Epoch 76 / 200 loss: 58.969990730285645\n",
      "MSE train 14.618013276158305 MSE test 17.13557971215281\n",
      "Epoch 77 / 200 loss: 58.30131816864014\n",
      "MSE train 14.45650672133067 MSE test 16.967863293205077\n",
      "Epoch 78 / 200 loss: 57.64627170562744\n",
      "MSE train 14.298052309423108 MSE test 16.802693389093168\n",
      "Epoch 79 / 200 loss: 57.00374412536621\n",
      "MSE train 14.142529796050516 MSE test 16.639930060560495\n",
      "Epoch 80 / 200 loss: 56.37307929992676\n",
      "MSE train 13.989862272328185 MSE test 16.47956224632301\n",
      "Epoch 81 / 200 loss: 55.75409126281738\n",
      "MSE train 13.839861684304713 MSE test 16.321832066723815\n",
      "Epoch 82 / 200 loss: 55.146483421325684\n",
      "MSE train 13.692183665690198 MSE test 16.16707016532802\n",
      "Epoch 83 / 200 loss: 54.549312591552734\n",
      "MSE train 13.546452284472377 MSE test 16.015284356615588\n",
      "Epoch 84 / 200 loss: 53.961039543151855\n",
      "MSE train 13.402400812328326 MSE test 15.86616713516506\n",
      "Epoch 85 / 200 loss: 53.380242347717285\n",
      "MSE train 13.259951918761613 MSE test 15.719425950284187\n",
      "Epoch 86 / 200 loss: 52.80611228942871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 13.11923849574475 MSE test 15.574907673445454\n",
      "Epoch 87 / 200 loss: 52.23862075805664\n",
      "MSE train 12.98050317729262 MSE test 15.432573527859075\n",
      "Epoch 88 / 200 loss: 51.6784029006958\n",
      "MSE train 12.843924703169913 MSE test 15.292449071210905\n",
      "Epoch 89 / 200 loss: 51.12625694274902\n",
      "MSE train 12.709574430496744 MSE test 15.154585090053773\n",
      "Epoch 90 / 200 loss: 50.58271789550781\n",
      "MSE train 12.577418436290909 MSE test 15.019042979800311\n",
      "Epoch 91 / 200 loss: 50.04801273345947\n",
      "MSE train 12.447345602061423 MSE test 14.885771604280762\n",
      "Epoch 92 / 200 loss: 49.521888732910156\n",
      "MSE train 12.319320895447712 MSE test 14.75453486962732\n",
      "Epoch 93 / 200 loss: 49.00375938415527\n",
      "MSE train 12.193539249417071 MSE test 14.625140773481732\n",
      "Epoch 94 / 200 loss: 48.49358081817627\n",
      "MSE train 12.070272402319883 MSE test 14.497595131591833\n",
      "Epoch 95 / 200 loss: 47.99240970611572\n",
      "MSE train 11.949528691292752 MSE test 14.37195354952945\n",
      "Epoch 96 / 200 loss: 47.501376152038574\n",
      "MSE train 11.831025841800935 MSE test 14.2482066166021\n",
      "Epoch 97 / 200 loss: 47.02037525177002\n",
      "MSE train 11.714323663445319 MSE test 14.12627105890386\n",
      "Epoch 98 / 200 loss: 46.548216819763184\n",
      "MSE train 11.598931548020397 MSE test 14.005978250237646\n",
      "Epoch 99 / 200 loss: 46.08312129974365\n",
      "MSE train 11.484517215689463 MSE test 13.887123480651704\n",
      "Epoch 100 / 200 loss: 45.623233795166016\n",
      "MSE train 11.37105894437289 MSE test 13.769561284839739\n",
      "Epoch 101 / 200 loss: 45.16740131378174\n",
      "MSE train 11.25868981864636 MSE test 13.653238517716755\n",
      "Epoch 102 / 200 loss: 44.71545124053955\n",
      "MSE train 11.14758954461112 MSE test 13.53822627419304\n",
      "Epoch 103 / 200 loss: 44.2677059173584\n",
      "MSE train 11.037994438924418 MSE test 13.424687153967612\n",
      "Epoch 104 / 200 loss: 43.82502365112305\n",
      "MSE train 10.930059099597655 MSE test 13.312665929758884\n",
      "Epoch 105 / 200 loss: 43.38848686218262\n",
      "MSE train 10.823797712131313 MSE test 13.202001052188947\n",
      "Epoch 106 / 200 loss: 42.958624839782715\n",
      "MSE train 10.7191630236084 MSE test 13.092507863111148\n",
      "Epoch 107 / 200 loss: 42.53530502319336\n",
      "MSE train 10.616101783332445 MSE test 12.984262841911242\n",
      "Epoch 108 / 200 loss: 42.118207931518555\n",
      "MSE train 10.514522765789291 MSE test 12.877796751124743\n",
      "Epoch 109 / 200 loss: 41.707027435302734\n",
      "MSE train 10.4143108927223 MSE test 12.773612778124306\n",
      "Epoch 110 / 200 loss: 41.30137825012207\n",
      "MSE train 10.315495883922944 MSE test 12.67144791929298\n",
      "Epoch 111 / 200 loss: 40.900936126708984\n",
      "MSE train 10.21833366839522 MSE test 12.57079317925123\n",
      "Epoch 112 / 200 loss: 40.506104469299316\n",
      "MSE train 10.122994855995339 MSE test 12.4714250305091\n",
      "Epoch 113 / 200 loss: 40.11793804168701\n",
      "MSE train 10.029333138260068 MSE test 12.373217214502164\n",
      "Epoch 114 / 200 loss: 39.73678684234619\n",
      "MSE train 9.937094315253388 MSE test 12.276062890621072\n",
      "Epoch 115 / 200 loss: 39.36187934875488\n",
      "MSE train 9.846063241080245 MSE test 12.179885038667448\n",
      "Epoch 116 / 200 loss: 38.99227523803711\n",
      "MSE train 9.75608181075883 MSE test 12.08462579811162\n",
      "Epoch 117 / 200 loss: 38.627243995666504\n",
      "MSE train 9.667032950869878 MSE test 11.990224444530057\n",
      "Epoch 118 / 200 loss: 38.2662467956543\n",
      "MSE train 9.578835653056606 MSE test 11.896601947511558\n",
      "Epoch 119 / 200 loss: 37.908867835998535\n",
      "MSE train 9.491472910833478 MSE test 11.803674459554024\n",
      "Epoch 120 / 200 loss: 37.554837226867676\n",
      "MSE train 9.405012538346202 MSE test 11.711389474227351\n",
      "Epoch 121 / 200 loss: 37.20418739318848\n",
      "MSE train 9.319566625638819 MSE test 11.61974963979106\n",
      "Epoch 122 / 200 loss: 36.85725021362305\n",
      "MSE train 9.235204464215483 MSE test 11.528818207080644\n",
      "Epoch 123 / 200 loss: 36.51444911956787\n",
      "MSE train 9.15190631943315 MSE test 11.438717370505305\n",
      "Epoch 124 / 200 loss: 36.175923347473145\n",
      "MSE train 9.069566476825457 MSE test 11.349596410588413\n",
      "Epoch 125 / 200 loss: 35.841407775878906\n",
      "MSE train 8.988018055134315 MSE test 11.261533718601864\n",
      "Epoch 126 / 200 loss: 35.51033401489258\n",
      "MSE train 8.907103060718514 MSE test 11.1744887810817\n",
      "Epoch 127 / 200 loss: 35.18201160430908\n",
      "MSE train 8.826756799263892 MSE test 11.088415228107744\n",
      "Epoch 128 / 200 loss: 34.85598278045654\n",
      "MSE train 8.747103828208001 MSE test 11.003336908064266\n",
      "Epoch 129 / 200 loss: 34.53230857849121\n",
      "MSE train 8.668540878220773 MSE test 10.919317814411945\n",
      "Epoch 130 / 200 loss: 34.21189594268799\n",
      "MSE train 8.591389565087784 MSE test 10.836451756245113\n",
      "Epoch 131 / 200 loss: 33.89648723602295\n",
      "MSE train 8.515710545761022 MSE test 10.754858738142973\n",
      "Epoch 132 / 200 loss: 33.58707141876221\n",
      "MSE train 8.441444042284745 MSE test 10.67461538631333\n",
      "Epoch 133 / 200 loss: 33.28365230560303\n",
      "MSE train 8.368425779632167 MSE test 10.595633580205316\n",
      "Epoch 134 / 200 loss: 32.985724449157715\n",
      "MSE train 8.296483547096175 MSE test 10.517743056803596\n",
      "Epoch 135 / 200 loss: 32.69241189956665\n",
      "MSE train 8.225487026394294 MSE test 10.440796532050795\n",
      "Epoch 136 / 200 loss: 32.40293025970459\n",
      "MSE train 8.1553367206789 MSE test 10.36472482229906\n",
      "Epoch 137 / 200 loss: 32.11673355102539\n",
      "MSE train 8.085920352788344 MSE test 10.289589813656196\n",
      "Epoch 138 / 200 loss: 31.83346700668335\n",
      "MSE train 8.017034180532312 MSE test 10.21552783324848\n",
      "Epoch 139 / 200 loss: 31.55274534225464\n",
      "MSE train 7.948425230616567 MSE test 10.142558798287435\n",
      "Epoch 140 / 200 loss: 31.273898601531982\n",
      "MSE train 7.880215499081355 MSE test 10.070636310698667\n",
      "Epoch 141 / 200 loss: 30.996299266815186\n",
      "MSE train 7.812998511121103 MSE test 9.999931415108673\n",
      "Epoch 142 / 200 loss: 30.72092628479004\n",
      "MSE train 7.7467787201502105 MSE test 9.930424984266299\n",
      "Epoch 143 / 200 loss: 30.44979476928711\n",
      "MSE train 7.681124417534151 MSE test 9.861790270223187\n",
      "Epoch 144 / 200 loss: 30.182416439056396\n",
      "MSE train 7.615785240572712 MSE test 9.793804983169176\n",
      "Epoch 145 / 200 loss: 29.917198657989502\n",
      "MSE train 7.550880147059577 MSE test 9.726459289779536\n",
      "Epoch 146 / 200 loss: 29.653439044952393\n",
      "MSE train 7.486681782039148 MSE test 9.659901425184847\n",
      "Epoch 147 / 200 loss: 29.391695499420166\n",
      "MSE train 7.4233771053870425 MSE test 9.594326985286063\n",
      "Epoch 148 / 200 loss: 29.132976531982422\n",
      "MSE train 7.361189939623248 MSE test 9.529925621202713\n",
      "Epoch 149 / 200 loss: 28.878376960754395\n",
      "MSE train 7.3002484646991626 MSE test 9.466728333869769\n",
      "Epoch 150 / 200 loss: 28.62904453277588\n",
      "MSE train 7.240494828038637 MSE test 9.404559466017524\n",
      "Epoch 151 / 200 loss: 28.3852219581604\n",
      "MSE train 7.181834741009788 MSE test 9.343177842207954\n",
      "Epoch 152 / 200 loss: 28.146236419677734\n",
      "MSE train 7.1242421696531535 MSE test 9.282415011455608\n",
      "Epoch 153 / 200 loss: 27.91143560409546\n",
      "MSE train 7.067737393195329 MSE test 9.222238282366614\n",
      "Epoch 154 / 200 loss: 27.68063735961914\n",
      "MSE train 7.012279994338038 MSE test 9.162706346201693\n",
      "Epoch 155 / 200 loss: 27.45391082763672\n",
      "MSE train 6.957706016409319 MSE test 9.103861050687659\n",
      "Epoch 156 / 200 loss: 27.23102855682373\n",
      "MSE train 6.903785912922888 MSE test 9.045680965091798\n",
      "Epoch 157 / 200 loss: 27.01130247116089\n",
      "MSE train 6.850288233148483 MSE test 8.988111493796882\n",
      "Epoch 158 / 200 loss: 26.793827056884766\n",
      "MSE train 6.797001664276162 MSE test 8.931101476141958\n",
      "Epoch 159 / 200 loss: 26.57768964767456\n",
      "MSE train 6.743777009377887 MSE test 8.874634896407159\n",
      "Epoch 160 / 200 loss: 26.362067222595215\n",
      "MSE train 6.690644135362561 MSE test 8.818774274315736\n",
      "Epoch 161 / 200 loss: 26.146456241607666\n",
      "MSE train 6.637826504880279 MSE test 8.763654589480428\n",
      "Epoch 162 / 200 loss: 25.931249618530273\n",
      "MSE train 6.585512163670787 MSE test 8.7093443004195\n",
      "Epoch 163 / 200 loss: 25.717626571655273\n",
      "MSE train 6.533772660060292 MSE test 8.65584456410437\n",
      "Epoch 164 / 200 loss: 25.506441593170166\n",
      "MSE train 6.482547281425591 MSE test 8.603177353725016\n",
      "Epoch 165 / 200 loss: 25.297860145568848\n",
      "MSE train 6.43174861575857 MSE test 8.55135523593264\n",
      "Epoch 166 / 200 loss: 25.09144639968872\n",
      "MSE train 6.381459047784048 MSE test 8.500393996636806\n",
      "Epoch 167 / 200 loss: 24.886826038360596\n",
      "MSE train 6.331886297942123 MSE test 8.450283332523908\n",
      "Epoch 168 / 200 loss: 24.68434190750122\n",
      "MSE train 6.283162061842074 MSE test 8.400910287695346\n",
      "Epoch 169 / 200 loss: 24.48466157913208\n",
      "MSE train 6.235298282197791 MSE test 8.352108949172882\n",
      "Epoch 170 / 200 loss: 24.288082599639893\n",
      "MSE train 6.188238040671098 MSE test 8.303822028541294\n",
      "Epoch 171 / 200 loss: 24.094590187072754\n",
      "MSE train 6.14189034398925 MSE test 8.256199032140275\n",
      "Epoch 172 / 200 loss: 23.9040470123291\n",
      "MSE train 6.096145768504849 MSE test 8.209453234401868\n",
      "Epoch 173 / 200 loss: 23.716240882873535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.0508655220432646 MSE test 8.163596663766532\n",
      "Epoch 174 / 200 loss: 23.530885219573975\n",
      "MSE train 6.005875313662692 MSE test 8.118422764655906\n",
      "Epoch 175 / 200 loss: 23.34753131866455\n",
      "MSE train 5.961040137302342 MSE test 8.073722463685941\n",
      "Epoch 176 / 200 loss: 23.165541172027588\n",
      "MSE train 5.9164363070066655 MSE test 8.029444485216244\n",
      "Epoch 177 / 200 loss: 22.98439359664917\n",
      "MSE train 5.8724092441685345 MSE test 7.985704628226658\n",
      "Epoch 178 / 200 loss: 22.80437660217285\n",
      "MSE train 5.829217053321369 MSE test 7.942639906136846\n",
      "Epoch 179 / 200 loss: 22.626726627349854\n",
      "MSE train 5.786820864639881 MSE test 7.900267641036092\n",
      "Epoch 180 / 200 loss: 22.452214241027832\n",
      "MSE train 5.7451111359286235 MSE test 7.858547443627094\n",
      "Epoch 181 / 200 loss: 22.280601501464844\n",
      "MSE train 5.704011675547893 MSE test 7.817447743517046\n",
      "Epoch 182 / 200 loss: 22.111519813537598\n",
      "MSE train 5.663465714830038 MSE test 7.776942816483443\n",
      "Epoch 183 / 200 loss: 21.944735050201416\n",
      "MSE train 5.623445183094406 MSE test 7.73700869356851\n",
      "Epoch 184 / 200 loss: 21.78008508682251\n",
      "MSE train 5.583960981288783 MSE test 7.697630292511914\n",
      "Epoch 185 / 200 loss: 21.617536544799805\n",
      "MSE train 5.545045530434262 MSE test 7.658802533313003\n",
      "Epoch 186 / 200 loss: 21.4572114944458\n",
      "MSE train 5.506722851563918 MSE test 7.620520035498225\n",
      "Epoch 187 / 200 loss: 21.29929208755493\n",
      "MSE train 5.468989296292738 MSE test 7.582765354184043\n",
      "Epoch 188 / 200 loss: 21.143882274627686\n",
      "MSE train 5.431818578657847 MSE test 7.545506444906165\n",
      "Epoch 189 / 200 loss: 20.990963459014893\n",
      "MSE train 5.395184268933189 MSE test 7.508705568976201\n",
      "Epoch 190 / 200 loss: 20.840425968170166\n",
      "MSE train 5.359073852699215 MSE test 7.4723268058603605\n",
      "Epoch 191 / 200 loss: 20.69216775894165\n",
      "MSE train 5.323475691264701 MSE test 7.436339059808044\n",
      "Epoch 192 / 200 loss: 20.546138286590576\n",
      "MSE train 5.288358959567719 MSE test 7.400708190687193\n",
      "Epoch 193 / 200 loss: 20.402267932891846\n",
      "MSE train 5.253677239671087 MSE test 7.365396670397791\n",
      "Epoch 194 / 200 loss: 20.260382652282715\n",
      "MSE train 5.219381769352835 MSE test 7.330367356671333\n",
      "Epoch 195 / 200 loss: 20.12025213241577\n",
      "MSE train 5.18542270454579 MSE test 7.295586708910917\n",
      "Epoch 196 / 200 loss: 19.98165273666382\n",
      "MSE train 5.1517465058019285 MSE test 7.261022695075581\n",
      "Epoch 197 / 200 loss: 19.84437894821167\n",
      "MSE train 5.118297080323479 MSE test 7.226646091127111\n",
      "Epoch 198 / 200 loss: 19.708231925964355\n",
      "MSE train 5.085023797908276 MSE test 7.192434429090938\n",
      "Epoch 199 / 200 loss: 19.573015213012695\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(hm_epochs):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i in range(int(tot_images/batch_size)):\n",
    "        epoch_x = X_train[ i*batch_size : (i+1)*batch_size ]\n",
    "        _, c = sess.run([optimizer, meansq],\\\n",
    "               feed_dict={input_layer: epoch_x, \\\n",
    "               output_true: epoch_x})\n",
    "        epoch_loss += c\n",
    "        \n",
    "    output_train = sess.run(output_layer,\\\n",
    "               feed_dict={input_layer:X_train})\n",
    "    output_test = sess.run(output_layer,\\\n",
    "                   feed_dict={input_layer:X_test})\n",
    "        \n",
    "    print('MSE train', MSE(output_train, X_train),'MSE test', MSE(output_test, X_test))      \n",
    "    print('Epoch', epoch, '/', hm_epochs, 'loss:',epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = pd.DataFrame()\n",
    "preds = sess.run(output_layer, feed_dict={input_layer: user_movie_matrix})\n",
    "pred_data = pred_data.append(pd.DataFrame(preds))\n",
    "pred_data = pred_data.stack().reset_index(name='rating')\n",
    "pred_data.columns = ['userId', 'title', 'rating']\n",
    "users = user_movie_matrix.index.tolist()\n",
    "movies = user_movie_matrix.columns.tolist()\n",
    "pred_data['userId'] = pred_data['userId'].map(lambda value: users[value])\n",
    "pred_data['title'] = pred_data['title'].map(lambda value: movies[value])\n",
    "keys = ['userId', 'title']\n",
    "index_1 = pred_data.set_index(keys).index\n",
    "index_2 = ur20plus.set_index(keys).index\n",
    "top_ten_ranked = pred_data[~index_1.isin(index_2)]\n",
    "top_ten_ranked = top_ten_ranked.sort_values(['userId', 'rating'], ascending=[True, False])\n",
    "top_ten_ranked = top_ten_ranked.groupby('userId').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>735089</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Scary Movie 2 (2001)</td>\n",
       "      <td>10.734091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734378</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Crimson Tide (1995)</td>\n",
       "      <td>9.428560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735156</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Solaris (2002)</td>\n",
       "      <td>7.677377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734358</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Collateral (2004)</td>\n",
       "      <td>7.309671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734459</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Dune (1984)</td>\n",
       "      <td>7.200686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735351</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Wedding Singer, The (1998)</td>\n",
       "      <td>6.868629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734836</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Maverick (1994)</td>\n",
       "      <td>6.576529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735385</th>\n",
       "      <td>9999999</td>\n",
       "      <td>X-Men: The Last Stand (2006)</td>\n",
       "      <td>6.514274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734159</th>\n",
       "      <td>9999999</td>\n",
       "      <td>American Gangster (2007)</td>\n",
       "      <td>6.435902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735387</th>\n",
       "      <td>9999999</td>\n",
       "      <td>Yes Man (2008)</td>\n",
       "      <td>6.374254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId                         title     rating\n",
       "735089  9999999          Scary Movie 2 (2001)  10.734091\n",
       "734378  9999999           Crimson Tide (1995)   9.428560\n",
       "735156  9999999                Solaris (2002)   7.677377\n",
       "734358  9999999             Collateral (2004)   7.309671\n",
       "734459  9999999                   Dune (1984)   7.200686\n",
       "735351  9999999    Wedding Singer, The (1998)   6.868629\n",
       "734836  9999999               Maverick (1994)   6.576529\n",
       "735385  9999999  X-Men: The Last Stand (2006)   6.514274\n",
       "734159  9999999      American Gangster (2007)   6.435902\n",
       "735387  9999999                Yes Man (2008)   6.374254"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_ranked.loc[top_ten_ranked['userId'] == 9999999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus = ur20plus.append(pd.DataFrame([[\"Hulk (2003)\",1,9999991,4370,5,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)\n",
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float)\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "ur20plus['rating'] = rating_scaled\n",
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title'])\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "user_movie_matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = pd.DataFrame()\n",
    "preds = sess.run(output_layer, feed_dict={input_layer: user_movie_matrix})\n",
    "pred_data = pred_data.append(pd.DataFrame(preds))\n",
    "pred_data = pred_data.stack().reset_index(name='rating')\n",
    "pred_data.columns = ['userId', 'title', 'rating']\n",
    "users = user_movie_matrix.index.tolist()\n",
    "movies = user_movie_matrix.columns.tolist()\n",
    "pred_data['userId'] = pred_data['userId'].map(lambda value: users[value])\n",
    "pred_data['title'] = pred_data['title'].map(lambda value: movies[value])\n",
    "keys = ['userId', 'title']\n",
    "index_1 = pred_data.set_index(keys).index\n",
    "index_2 = ur20plus.set_index(keys).index\n",
    "top_ten_ranked = pred_data[~index_1.isin(index_2)]\n",
    "top_ten_ranked = top_ten_ranked.sort_values(['userId', 'rating'], ascending=[True, False])\n",
    "top_ten_ranked = top_ten_ranked.groupby('userId').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>734836</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Maverick (1994)</td>\n",
       "      <td>8.735404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734944</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Omen, The (1976)</td>\n",
       "      <td>7.697131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734536</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>7.527423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735227</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Talladega Nights: The Ballad of Ricky Bobby (2...</td>\n",
       "      <td>7.485170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735020</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Rain Man (1988)</td>\n",
       "      <td>7.321448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734750</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Kung Fu Panda (2008)</td>\n",
       "      <td>7.252985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735328</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Virgin Suicides, The (1999)</td>\n",
       "      <td>6.782855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735025</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Reality Bites (1994)</td>\n",
       "      <td>6.664783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734997</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Predator 2 (1990)</td>\n",
       "      <td>6.609117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734137</th>\n",
       "      <td>9999991</td>\n",
       "      <td>Adventures of Priscilla, Queen of the Desert, ...</td>\n",
       "      <td>6.509538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId                                              title    rating\n",
       "734836  9999991                                    Maverick (1994)  8.735404\n",
       "734944  9999991                                   Omen, The (1976)  7.697131\n",
       "734536  9999991                                  Four Rooms (1995)  7.527423\n",
       "735227  9999991  Talladega Nights: The Ballad of Ricky Bobby (2...  7.485170\n",
       "735020  9999991                                    Rain Man (1988)  7.321448\n",
       "734750  9999991                               Kung Fu Panda (2008)  7.252985\n",
       "735328  9999991                        Virgin Suicides, The (1999)  6.782855\n",
       "735025  9999991                               Reality Bites (1994)  6.664783\n",
       "734997  9999991                                  Predator 2 (1990)  6.609117\n",
       "734137  9999991  Adventures of Priscilla, Queen of the Desert, ...  6.509538"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_ranked.loc[top_ten_ranked['userId'] == 9999991] #an example of the top 10 recommendations for the above new user who only rated one movie, i.e., \"Hulk (2003)\", with a 5/5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus = ur20plus.append(pd.DataFrame([[\"Hulk (2003)\",1,9999992,4370,5,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)\n",
    "ur20plus = ur20plus.append(pd.DataFrame([[\"Aliens (1986)\",1,9999992,4370,3,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)\n",
    "ur20plus = ur20plus.append(pd.DataFrame([[\"Brave (2012)\",1,9999992,4370,4,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)\n",
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float)\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "ur20plus['rating'] = rating_scaled\n",
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title'])\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "user_movie_matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = pd.DataFrame()\n",
    "preds = sess.run(output_layer, feed_dict={input_layer: user_movie_matrix})\n",
    "pred_data = pred_data.append(pd.DataFrame(preds))\n",
    "pred_data = pred_data.stack().reset_index(name='rating')\n",
    "pred_data.columns = ['userId', 'title', 'rating']\n",
    "users = user_movie_matrix.index.tolist()\n",
    "movies = user_movie_matrix.columns.tolist()\n",
    "pred_data['userId'] = pred_data['userId'].map(lambda value: users[value])\n",
    "pred_data['title'] = pred_data['title'].map(lambda value: movies[value])\n",
    "keys = ['userId', 'title']\n",
    "index_1 = pred_data.set_index(keys).index\n",
    "index_2 = ur20plus.set_index(keys).index\n",
    "top_ten_ranked = pred_data[~index_1.isin(index_2)]\n",
    "top_ten_ranked = top_ten_ranked.sort_values(['userId', 'rating'], ascending=[True, False])\n",
    "top_ten_ranked = top_ten_ranked.groupby('userId').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>735833</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>13.103753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736047</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Kung Fu Panda (2008)</td>\n",
       "      <td>8.568954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736682</th>\n",
       "      <td>9999992</td>\n",
       "      <td>X-Men: The Last Stand (2006)</td>\n",
       "      <td>8.504925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736524</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Talladega Nights: The Ballad of Ricky Bobby (2...</td>\n",
       "      <td>8.497384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735724</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Dirty Dozen, The (1967)</td>\n",
       "      <td>8.466221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735420</th>\n",
       "      <td>9999992</td>\n",
       "      <td>6th Day, The (2000)</td>\n",
       "      <td>8.337077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735625</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Charlie's Angels: Full Throttle (2003)</td>\n",
       "      <td>8.259453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736257</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Peacemaker, The (1997)</td>\n",
       "      <td>8.158257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735484</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Armageddon (1998)</td>\n",
       "      <td>7.902801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736317</th>\n",
       "      <td>9999992</td>\n",
       "      <td>Rain Man (1988)</td>\n",
       "      <td>7.900194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId                                              title     rating\n",
       "735833  9999992                                  Four Rooms (1995)  13.103753\n",
       "736047  9999992                               Kung Fu Panda (2008)   8.568954\n",
       "736682  9999992                       X-Men: The Last Stand (2006)   8.504925\n",
       "736524  9999992  Talladega Nights: The Ballad of Ricky Bobby (2...   8.497384\n",
       "735724  9999992                            Dirty Dozen, The (1967)   8.466221\n",
       "735420  9999992                                6th Day, The (2000)   8.337077\n",
       "735625  9999992             Charlie's Angels: Full Throttle (2003)   8.259453\n",
       "736257  9999992                             Peacemaker, The (1997)   8.158257\n",
       "735484  9999992                                  Armageddon (1998)   7.902801\n",
       "736317  9999992                                    Rain Man (1988)   7.900194"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_ranked.loc[top_ten_ranked['userId'] == 9999992] #an example of the top 10 recommendations for the above new user who rated three movies, i.e., \"Hulk (2003)\" with a 5/5, \"Aliens (1986)\" with a 3/5, and \"Brave (2012)\" with a 4/5."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
